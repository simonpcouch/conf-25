session_type,session_title,abstract_text
Breakout Session,"Beautiful, Effective, and Accessible Data Visualization","## Title: History repeats itself: What the Du Bois Challenge taught me about reproducing visualisations
**Code:** PAR-006
**Session type:** Breakout Session

**Abstract:**
In 2024, I participated in the Du Bois challenge to recreate W.E.B Du Bois’s iconic 1900s charts on African American sociology. By reproducing the old graphs and their annotations, themes, accessibility and visible contrasts, I levelled up my visualisation skills. I learnt about complexity of design, colour palettes, fonts, styling, and of course appropriate R packages. This experience empowered me beyond the DuBois challenge and used what I learnt to take part in the 30-day chart challenge, Genuary and Tidy Tuesday. In this talk, I will share what I learnt so that you too can more easily become familiar with unfamiliar charts and craft your own visualizations to regale stories.

**Speaker name:** Simisani Ndaba
**Job title:** Teaching Assistant | Data Science Research Assistant
**Company:** University of Botswana
**Bio:**
Simisani Ndaba works as a part time Data Science Researcher at the Department of Engineering and Technology and as a Teaching Assistant in the Department of Computer Science at the University of Botswana. She is a PhD student at the Botswana International University of Science and Technology with her research focusing on bio-inspired methods for Optimisation challenges. She is an active member in the R-Ladies Global community and founder of the R-Ladies Gaborone chapter.

## Title: Visualizing Nuuk: Finding Narrative in Public Registers
**Code:** PAR-006
**Session type:** Breakout Session

**Abstract:**
Good graphs are more than simple decorations. They are effective tools for challenging your intuition, and can uncover engaging narratives along the way. Using examples from official statistics, this talk shows how tools like API packages can query data from official registers, streamlining ways to import and tidy data, so your time is better spent on story telling with data visualisation.
Highlighting Nuuk, a symbol of Greenland's rapid change, I'll demonstrate how to use these tools to turn complex registers into clear, impactful stories. If you work with official statistics, as an educator, journalist or in government, this talk offers practical insights for streamlining workflows and crafting engaging visualizations.

**Speaker name:** Emil Malta
**Job title:** Senior Consultant
**Company:** Statistics Greenland
**Bio:**
Emil is a senior data consultant with a background in bioinformatics, known for creating visuals that make complex data more accessible. With experience across healthcare sourcing, and national statistics, Emil brings a thoughtful, hands-on approach to visual storytelling and data exploration.

## Title: maidr: Empowering Accessible, Multimodal Data Visualizations
**Code:** PAR-006
**Session type:** Breakout Session

**Abstract:**
maidr is a Python package that transforms visualizations into accessible multimodal representations. Designed for both blind/low-vision and sighted users, it integrates with libraries like matplotlib and seaborn and supports interactive environments such as Quarto, Jupyter Notebooks, Google Colab, Streamlit, and Shiny. With a simple function call, maidr synchronizes visual, tactile (Braille), textual, audible (sonification), and conversational outputs, enabling reproducible, inclusive workflows. By creating, modifying and sharing accessible visualizations, maidr fosters collaborative insights by bridging the gap between blind/low-vision and sighted users, empowering inclusive, data-driven decision-making that leverages diverse perspectives.

**Speaker name:** JooYoung Seo
**Job title:** Assistant Professor
**Company:** University of Illinois at Urbana-Champaign
**Bio:**
NA

## Title: Same Data, Different Tools: Visualizing with R and Python
**Code:** PAR-006
**Session type:** Breakout Session

**Abstract:**
In 2024, our team participated in a data challenge to recreate a visualization from W.E.B. Du Bois’s 1900 Paris Exposition using modern tools. We split into two groups—one using R and the other Python—to compare their strengths and limitations. Both teams used census and geographic data to map county-level populations for 1870 and 1880. Team R used ggplot2 and grid for precise layout control, while Team Python used matplotlib’s subplot system for structuring. This challenge pushed us beyond more traditional data science visualizations, requiring creative approaches to mimic Du Bois’s design. Attendees will gain insights into data wrangling, visualization techniques, and layout design to guide their own projects.

**Speaker name:** Olivia Hebner
**Job title:** Data Science Manager
**Company:** Summit Consulting
**Bio:**
NA"
Breakout Session,Data for Real-World Impact,"## Title: Elevating Public Health Decision-Making with R Packages
**Code:** PAR-004
**Session type:** Breakout Session

**Abstract:**
Supporting public health decisions in high-stakes environments requires transparency, reproducibility, and efficiency. Analyzing real-world health data with complex models helps policymakers mitigate infectious disease spread. Structuring projects as R packages provides a consistent framework that enhances organization, integrates documentation, and facilitates collaboration. This approach improves coding practices, ensures reproducibility, and enables seamless sharing of tools—empowering colleagues without the resources to develop their own. This talk will demonstrate how adopting R package structures can enhance workflows and impact without requiring advanced software development skills.

**Speaker name:** Kylie Ainslie
**Job title:** Senior Researcher
**Company:** Dutch National Institute of Public Health and the Environment (RIVM)
**Bio:**
Kylie Ainslie is an infectious disease modeller at the Dutch National Institute of Public Health and the Environment (RIVM) and an Honorary Assistant Professor at the University of Hong Kong. She applies mathematical and statistical methods to study how infectious diseases spread, focusing on key epidemiological quantities and intervention impacts. Her research examines vaccine effectiveness over time and vaccination strategies for diseases like COVID-19 and influenza. She's passionate about open-source, reproducible research, and is currently working towards developing her first R package for CRAN submission.

## Title: Data 911: how Posit can support decision-makers in times of environmental crisis
**Code:** PAR-004
**Session type:** Breakout Session

**Abstract:**
Over 200 million gallons of mining wastewater was released into Tampa Bay in March of 2021.  Concerns about the environmental impacts prompted a multi-agency response to monitor water quality changes in the bay, producing thousands of sample points in need of synthesis and communication to a concerned public. This talk will describe how the Tampa Bay Estuary Program leveraged Posit products to create a data synthesis workflow and Shiny dashboard to inform decision-makers on how, where, and when water quality was affected by this pollution.  Our experience navigating this event in real time will be shared with the broader community as a successful example of how Posit products can address environmental crises.

**Speaker name:** Marcus Beck
**Job title:** Senior Scientist
**Company:** Tampa Bay Estuary Program
**Bio:**
Marcus Beck is the Senior Scientist for the Tampa Bay Estuary Program in St. Petersburg, Florida and is developing data analysis and visualization methods for Bay health indicators. Marcus has experience researching environmental indicators and developing open science products to support decision-making in aquatic environments around the country, including Minnesota lakes, Florida estuaries, and California streams. He has been using the R statistical programming language for over 15 years and has taught several workshops on its application to environmental sciences. Marcus has also developed several R packages and currently maintains 9 on CRAN. He received a PhD in Conservation Biology with a minor in Statistics from the University of Minnesota in 2013, his Masters in Conservation Biology from the University of Minnesota in 2009, and his Bachelors in Zoology from the University of Florida in 2007.

## Title: See if talking to the doctor is right for you.
**Code:** PAR-004
**Session type:** Breakout Session

**Abstract:**
Clinicians and data professionals have different approaches to data which can lead to communication difficulties within a research team. This session will highlight common areas of confusion between data scientists and clinicians.  Several techniques will be reviewed to facilitate communication using several examples in R. There will also be a real, live-clinician who wants to hear from you and will apologize for the actions of any past clinician researchers.

**Speaker name:** Max Hockstein
**Job title:** Physician
**Company:** MedStar Health
**Bio:**
After being intimidated by the number and complexity of dynamic systems encountered in undergraduate pure and applied mathematics, Max Hockstein instead became an emergency medicine and critical care physician. He holds a master's degree in clinical and translational science which makes him question all of his prior life choices. Areas of research interest include: mechanical circulatory support, mechanical ventilation, and clinician-data scientists. Please teach him more R.

## Title: Election Night Reporting Using R & Quarto
**Code:** PAR-004
**Session type:** Breakout Session

**Abstract:**
Election night reporting (ENR) is often clunky, outdated, and overpriced. The Idaho Secretary of State’s office leveraged R and Quarto to create a better ENR product for the end user while driving down costs using the open-source software we all know and love. With help from Dr. Andrew Heiss, R was used in every step of the process—from {dbplyr} backend to visualizing the results using {reactable} tables and {leaflet} maps, combining the output into a visually appealing Quarto website. Quarto was the ideal solution due to its scalability, quick deployment, responsive design, and easy navigation. In addition, Dr. Heiss will discuss the advantages of using a {targets} pipeline and creating programmatic code chunks in Quarto.

**Speaker name:** Gabe Osterhout
**Job title:** Data Visualization Specialist
**Company:** Idaho Secretary of State
**Bio:**
Gabe Osterhout is the data visualization specialist at Idaho Secretary of State, where he analyzes voter, election, and campaign finance statistics. As a representative on the state’s geospatial council, Gabe evangelizes R’s powerful mapping packages to the ArcGIS faithful. He holds degrees from The College of Idaho and King’s College London.

## Title: Election Night Reporting Using R & Quarto
**Code:** PAR-004
**Session type:** Breakout Session

**Abstract:**
Election night reporting (ENR) is often clunky, outdated, and overpriced. The Idaho Secretary of State’s office leveraged R and Quarto to create a better ENR product for the end user while driving down costs using the open-source software we all know and love. With help from Dr. Andrew Heiss, R was used in every step of the process—from {dbplyr} backend to visualizing the results using {reactable} tables and {leaflet} maps, combining the output into a visually appealing Quarto website. Quarto was the ideal solution due to its scalability, quick deployment, responsive design, and easy navigation. In addition, Dr. Heiss will discuss the advantages of using a {targets} pipeline and creating programmatic code chunks in Quarto.

**Speaker name:** Andrew Heiss
**Job title:** Assistant professor
**Company:** Georgia State University
**Bio:**
Andrew Heiss is an assistant professor at the Andrew Young School of Policy Studies at Georgia State University. His research explores human rights and international nonprofit management and focuses on authoritarian regulation of civil society. He also studies and teaches quantitative research methods, causal inference, data visualization, and Bayesian analysis. He is an RStudio Certified Instructor and has been a Posit Academy Tidyverse Mentor since 2022."
Breakout Session,Enterprise Data Platforms,"## Title: Championing modern science workflows to benefit dairy farmers
**Code:** PAR-009
**Session type:** Breakout Session

**Abstract:**
Dairy research faces data volume and variability challenges. DairyNZ's Modern Science Workflows project addressed this via infrastructure, capability, and business disciplines. Infrastructure: Snowflake cloud data warehouse and Posit Workbench for R. Capability: R data science courses (Uni of Waikato & internal). Business: Meetings, documented code, best practices, and moving towards open science with GitHub at organisational level. Results: We have enabled large dataset projects utilising machine learning which would not have been possible before (e.g., animal sensor data analysis). Training has been well-received. Modern workflows enable reproducibility, and data science skills should become standard scientific training.

**Speaker name:** Mark Neal
**Job title:** Head of Data Science
**Company:** DairyNZ
**Bio:**
Mark works at DairyNZ, where our purpose is to progress a positive future for New Zealand dairy farming. The organisation delivers research, development, extension and advocacy. Mark’s role is Head of the Data Science and Modelling team. This team primarily supports the Research and Science team, but also has a wider role in the organisation to provide advanced analytical capability where it is needed. He comes from a strong grounding in dairy farming, having worked in management roles on his family’s farms in Australia, and on farms in Chile and in the United States.

## Title: The Power of Snowflake and Posit Workbench: Macroeconomic Data Exploration in the Cloud
**Code:** PAR-009
**Session type:** Breakout Session

**Abstract:**
In this talk, we will utilize the Posit Workbench Native App to demonstrate how macroeconomic research can be run in the Snowflake cloud, powered by R & RStudio. 
<br><br>
Starting with data sourced from the Snowflake marketplace, we will import, transform, visualize, and, finally, model data using the Orbital framework to push tidymodels down to the cloud. This is full-stack, R-driven macroeconomic research in the cloud.

**Speaker name:** Jonathan Regenstein
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: From Framework to Function: Integrating AI, Data Science Platforms, and Psychological Safety
**Code:** PAR-009
**Session type:** Breakout Session

**Abstract:**
Navigating the vast array of AI and data science tools can be daunting. This talk details our journey to address this challenge, starting with an enterprise data architecture and followed by the development an AI framework—a foundational layer of AI services. We advanced by integrating developer-preferred data science platforms, such as Posit Workbench and Posit Connect, alongside Databricks for centralized data governance. Our choices have enabled us to use Posit Workbench and Databricks to perform analyses and reporting with enhanced efficiency and alignment with modern architectures and governance standards. The rapid integration of these services was driven by a focus on psychological safety, a catalyst for enhancing team performance.

**Speaker name:** Chris Engelhardt
**Job title:** Sr. Data and AI Operations Manager
**Company:** Gen Re
**Bio:**
Chris is a Sr. Data and AI Operations Manager at Gen Re, where he leads a dynamic team comprising architects, engineers, data scientists, and full-stack developers. Together, they are dedicated to creating and implementing innovative data science and AI solutions. Additionally, Chris has been instrumental in organizing regular meet-ups for enthusiasts of R programming and AI development. He enjoys spending time with his two boys and watching them play baseball and soccer.

## Title: From SDKs to Agents: Building with R and Python on Databricks
**Code:** PAR-009
**Session type:** Breakout Session

**Abstract:**
Databricks offers a rich ecosystem of packages for R and Python developers. This session explores the key tools available—like {ellmer}, {brickster}, and the Databricks SDKs—helping developers build scalable workflows and AI-powered applications. Whether you're working in R or Python, you'll learn how to integrate your IDE, leverage Databricks-hosted LLMs, and build agentic workflows. We’ll cover practical implementations, best practices, and how to scale your projects using Databricks’ robust infrastructure. Whether you're automating workflows or deploying AI-driven solutions, this talk provides the essential toolkit for success.

**Speaker name:** Zac Davies
**Job title:** Lead Solutions Architect
**Company:** Databricks
**Bio:**
Zac Davies is a Lead Solutions Architect at Databricks. With a decade of big-data experience, he guides teams on scalable data & AI. An R open-source contributor, he maintains brickster and contributes to sparklyr, bridging R and the Lakehouse.

## Title: From SDKs to Agents: Building with R and Python on Databricks
**Code:** PAR-009
**Session type:** Breakout Session

**Abstract:**
Databricks offers a rich ecosystem of packages for R and Python developers. This session explores the key tools available—like {ellmer}, {brickster}, and the Databricks SDKs—helping developers build scalable workflows and AI-powered applications. Whether you're working in R or Python, you'll learn how to integrate your IDE, leverage Databricks-hosted LLMs, and build agentic workflows. We’ll cover practical implementations, best practices, and how to scale your projects using Databricks’ robust infrastructure. Whether you're automating workflows or deploying AI-driven solutions, this talk provides the essential toolkit for success.

**Speaker name:** Rafi Kurlansik
**Job title:** Data Science - ML Developer Experience
**Company:** 
**Bio:**
NA"
Breakout Session,Facepalm-driven Development: Learning From AI and Human Errors,"## Title: How I got unstuck with Python
**Code:** PAR-014
**Session type:** Breakout Session

**Abstract:**
Python as a language is known for being explicit, simple, readable, and beautiful. At the same time, the tooling around using and writing this language has not always made people feel productive and delighted. I know this has been true for me! In this talk, learn about recent improvements in tooling for Python that have finally addressed my own persistent challenges. Posit’s new IDE, Positron, provides a next generation environment for Python data practice, and this new IDE plays nicely with modern language tooling from the Python community. Whether you are Python curious or looking for ways to improve your Python workflows, hear about how I finally got myself unstuck with the most popular programming language in the world.

**Speaker name:** Julia Silge
**Job title:** Engineering Manager
**Company:** Posit, PBC
**Bio:**
<p>Julia Silge is a data scientist and engineering manager at Posit PBC where she works on open source tools for machine learning and data science, as well as an author and international keynote speaker. Julia loves text analysis, making beautiful charts, and communicating about technical topics with diverse audiences. You can find her online at her <a href=""https://juliasilge.com/"" rel=""noopener noreferrer"" target=""_blank"">blog</a> and <a href=""https://www.youtube.com/juliasilge"" rel=""noopener noreferrer"" target=""_blank"">YouTube</a>.</p>

## Title: Hacking Productivity with LLMs: What Works (and What Doesn’t)
**Code:** PAR-014
**Session type:** Breakout Session

**Abstract:**
Over the past 18 months, I've used large language models (LLMs) in a huge number of experiments to improve my skills as a developer, automate tedious tasks, and even navigate career shifts. Some of my experiments were wildly successful, but others were clear failures.
<br>In this talk, I'll share what worked, what didn't, and what I learned. I'll explore practical ways to test ideas quickly, compare R tools for working with LLMs, and discuss the circumstances in which LLMs are useful, and when they aren't as helpful as you might expect. Whether you're looking to boost productivity, streamline your work, or avoid common AI pitfalls, this talk will help you navigate the possibilities without the hype.

**Speaker name:** Nic Crane
**Job title:** R Consultant
**Company:** NC Data Labs
**Bio:**
Nic Crane is a data scientist, software engineer, and R consultant. Nic is part of the team who maintain the arrow R package and co-author of Scaling Up with R and Arrow.

## Title: AI missteps as stepping stones: Opportunities gained when your LLM coding assistant gets it wrong
**Code:** PAR-014
**Session type:** Breakout Session

**Abstract:**
LLM coding assistants have become a valuable companion for learning and productivity in data science. (Hey Siri! Import this csv!) While their ability to generate code and explanations is impressive, I have found more value and personal growth from the mistakes they make. 

This talk focuses on embracing coding assistants as imperfect companions and succeeding when they fail. I'll share insights from using these assistants to facilitate my transition to Python, highlighting the pitfalls of accepting their recommendations without question. Through real examples where LLMs fell short, I'll demonstrate how these challenges provided frameworks for problem-solving and led to a deeper understanding of data science tools and methodologies.

**Speaker name:** Ryan Timpe
**Job title:** Lead Data Scientist
**Company:** The LEGO Group
**Bio:**
A lifelong enthusiast of mathematics and those iconic plastic bricks, Ryan has proudly been a data scientist at the LEGO Group since 2019. In this role, he constructs data models to optimize sales and marketing strategies, promoting their usage across the business. Before joining LEGO, Ryan worked as a consultant, where he specialized in market sizing and forecasting within the tech industry. He holds a master’s degree in economics from Boston University.

## Title: Failure (and Mistakes)
**Code:** PAR-014
**Session type:** Breakout Session

**Abstract:**
In a field driven by precision, the power of failure is often overlooked. This talk digs into the paradoxical benefit of error in data science, drawing on high-profile missteps in data handling and personal anecdotes of falling short. Using examples from errors big and small leading to impacts big and small to the everyday misinterpretation or misuse of data that happens everywhere, we’ll focus on how to get the best out of failure. While some level of error is inevitable in data science, the most resilient and forward-thinking teams realize that errors can drive innovative and creative solutions that may not have been discovered if everything had gone as planned.

**Speaker name:** Laura Gast
**Job title:** Enterprise Data & Analytics Lead
**Company:** USO
**Bio:**
Technically an Epidemiologist, Dr. Gast has spent her career at the intersection of communicating technical work to non-technical (and often extremely busy) decision makers.

Laura has spent over a decade working on infectious disease control strategies and reporting frame works in more than 10 countries, including many in Southern Africa, honing her skills for effectively and efficiently communicating highly specific and technical details.

These days, you will find Laura working for a non-profit dedicated to serving US military members and their families, wrestling with development and impact data. In her free time, you’ll find her playing pub trivia, throwing darts, or going on a nice long run on the US Mall."
Breakout Session,Get Your Ducks in a Row with Databases,"## Title: duckplyr: Analyze large data with full dplyr compatibility
**Code:** PAR-007
**Session type:** Breakout Session

**Abstract:**
The duckplyr package is now stable, version 1.0.0 has been published on CRAN. Learn how to use this package to speed up your existing dplyr codes with little to no changes, and how to work with larger-than-memory data using a syntax that not only feels like dplyr for data frames, but behaves exactly like that.

**Speaker name:** Kirill Müller
**Job title:** Partner
**Company:** cynkra GmbH
**Bio:**
Kirill has been working on the boundary between data and computer science for more than 25 years and is co-founder and partner at cynkra, a Zurich-based data science consultancy.

## Title: Semantic Search for the Rest of Us with DuckDB
**Code:** PAR-007
**Session type:** Breakout Session

**Abstract:**
Semantic search matches a search query against documents not just by directly matching words, but by ranking results using semantic meaning  - for example searching for “cat” could also turn up documents that have “tiger.” 
<br><br>
While many enterprise level solutions exist for semantic search, I will show a low memory  technique in Python that enables live semantic search for small to medium document collections that need to be deployed in constrained memory/ CPU environments - such as Posit Connect Cloud or a small cloud server.
<br><br>
I will show how a web app (such as Shiny for Python) using just a few hundred megabytes of memory can enable live search using the fixed array support in DuckDB, and the open source library LlamaCPP.

**Speaker name:** Marcos Huerta
**Job title:** Manager, Data Science
**Company:** Carmax
**Bio:**
Marcos Huerta is a Data Science Manager at Carmax in Richmond, Virginia since 2019 where he works on pricing algorithms for the Core Pricing Systems team. He started working in data science in 2019 after completing the Data Incubator data science boot camp. Prior to his career in the private sector data, Marcos worked in science policy in Washington DC area, most recently for the U.S. Department of Energy.  He received a PhD in Astrophysics from Rice University and his undergraduate degree in astronomy from the University of Texas at Austin.

## Title: Keeping Data Alive: Persistent Storage Options for Dynamic Cloud Applications
**Code:** PAR-007
**Session type:** Breakout Session

**Abstract:**
Building cloud-based data applications that evolve over time requires persistent storage solutions. Without a way to record new information or modify datasets, applications like Shiny or Streamlit would reset after each session, losing potentially valuable information. This talk explores persistent storage options ranging from lightweight solutions like Google Sheets to scalable services like Amazon S3 and MotherDuck. We’ll also cover securing connections to these services using Posit Connect Cloud’s secret variable management. By the end, you’ll understand common persistent storage solutions, their trade-offs, and how to choose the best approach for your specific project.

**Speaker name:** Alex Chisholm
**Job title:** Product Manager, Cloud Platforms
**Company:** Posit
**Bio:**
Alex Chisholm is a data professional turned product manager. He works at Posit on Posit Cloud, shinyapps.io, and Connect Cloud, a new online publishing platform for data applications and documents. Prior to joining Posit, Alex lived in Amsterdam, NL where he worked for an online travel startup and an education insights company. He now lives in Pittsburgh, PA with his wife and two daughters.

## Title: Get your ducks in a row... faster Shiny apps with DuckDB
**Code:** PAR-007
**Session type:** Breakout Session

**Abstract:**
Our small team tackled sluggish Shiny applications by implementing DuckDB as a cache layer, transforming slow, resource-intensive operations into responsive user experiences. Initially, our application pulled data directly from SQL Server, performing real-time aggregations that resulted in poor response times. By restructuring our pipeline to pre-compute results in DuckDB, we significantly improved performance. This presentation demonstrates how we identified bottlenecks, implemented DuckDB integration, and measured improvements. We'll share practical examples of DuckDB integration with R, discuss trade-offs, and show how this accessible solution can benefit other small teams with limited resources.

**Speaker name:** Melissa Albino Hegeman
**Job title:** Data Analyst
**Company:** NYS OGS
**Bio:**
I am a data manager and geospatial analyst with 20+ years of experience. I am interested in data science, spatial planning, and sustainability and helping teams modernize their data systems."
Breakout Session,I Like Big Orgs and I Cannot Lie,"## Title: Data-as-a-product: A framework for collaborative data wrangling
**Code:** PAR-011
**Session type:** Breakout Session

**Abstract:**
Data preparation requires substantial time and subject matter expertise but is often tailored to a single-use deadline rather than encouraging reusable workflows across a team. We developed a framework that acknowledges the time and expertise invested in data preparation and maximizes its value. Our data-as-a-product suite of R packages promotes joint code and data version control, standardizes metadata capture, tracks R package versioning, and encourages best practices such as adherence to functional programming. I'm excited to share my experience onboarding collaborators to this reproducible research framework, highlighting key challenges and lessons learned from advocating for good development practices in a dynamic research environment.

**Speaker name:** Clara Amorosi
**Job title:** Principal Data Scientist
**Company:** Bristol Myers Squibb
**Bio:**
NA

## Title: SAS to R: It’s more than just coding
**Code:** PAR-011
**Session type:** Breakout Session

**Abstract:**
Switching from SAS to R is not just a technical shift – it requires a whole new way of thinking! This journey of moving a SAS-centered coding team to R was filled with strategies, challenges, and unexpected roadblocks. Change can be frustrating, but with the right mindset and approach, it becomes an opportunity for growth and empowerment. As a forward-thinking R strategist and advocate for growth, I am excited to help you discover practical strategies to ease the transition, overcome resistance and frustration, and empower teams to embrace R with confidence. Whether you team is starting on a similar path or is struggling, I will share insights on how to navigate challenges, avoid pitfalls, and hopefully leave you with a roadmap for success.

**Speaker name:** Yvonne Kienast
**Job title:** Project Lead
**Company:** Canadian Institute for Health Information (CIHI)
**Bio:**
NA

## Title: What R We Counting?
**Code:** PAR-011
**Session type:** Breakout Session

**Abstract:**
GSK Biostatistics mandates that all new tools be written using open-source languages and open-source code achieve parity with proprietary software by the end of 2025. Given this ambitious timeline, someone might ask, ""How is the open-source adoption going?"" This seemingly simple question involves complexities: What metrics do you track? How to measure success? How to show progress? GSK addressed these by leveraging our internal GitHub data, using open-source R packages like {gh}, scheduling our data pipeline on Posit Connect, and generating diverse reports/dashboards. We’ll share our journey of transitioning to R and other open-source tools, offering insights on scaling full enterprise open-source adoption.

**Speaker name:** Ben Arancibia
**Job title:** Director Data Science - Scientific and Adoption Lead for Open Source
**Company:** GSK
**Bio:**
Ben Arancibia is a Director of Data Science on GSK's Data Science Innovation and Engineering Team. Ben is a seasoned data scientist with 14+ years of experience utilizing open-source languages. His career includes building analytical products for international finance and cloud computing environments for cybersecurity. At GSK, he leads Open Source Adoption which includes developing tools for clinical trial analysis, focusing on innovative R training and upskilling approaches.

## Title: A tale of one organization: learning how to swim in the ocean of open source
**Code:** PAR-011
**Session type:** Breakout Session

**Abstract:**
The Canadian Institute for Health Information is diving into open source, transitioning our 300+ analysts and all our analytics code from proprietary software to R and Python. We started 3 years ago, and over that time we have migrated 700,000+ lines of code, navigating waves of change while adapting to new IT environments and workflows. Challenges like technical barriers, workload balancing, and resistance to change were tackled through training, mentorship, and executive support. More than tools, this shift transforms our culture—turning siloed developers into fearless swimmers. Success requires training, teamwork, and courage. Organizations making a similar leap should start small, invest in training, and stay adaptable to stay afloat.

**Speaker name:** Katerina Gapanenko
**Job title:** Manager, Advanced Analytics
**Company:** Canadian Institute for Health Information
**Bio:**
NA"
Breakout Session,It Takes a Village: Building and Sustaining Communities,"## Title: Running a polyglot data science community
**Code:** PAR-002
**Session type:** Breakout Session

**Abstract:**
Running a successful data science community is CHALLENGING! And it's even more challenging when you have a very large group of people, especially if they use different programming languages or are at different steps in their data journeys. It can be done, though, and in my talk I'll share the strategies that we've been using at Statistics Canada to keep the 1000+ members of our R and Python User Group interested and involved. I'll also talk about why you don't have to limit the target audience of your data science community to just one group -- creating *polyglot* communities that embrace multiple programming languages is a great way to ensure the long-term success and relevance of these groups.

**Speaker name:** Melissa Van Bussel
**Job title:** Senior Data Scientist
**Company:** Statistics Canada
**Bio:**
Melissa Van Bussel is a Senior Data Scientist at Statistics Canada, where she develops and delivers training about open-source languages and tools. She also helps run a large R and Python User Group at Statistics Canada. Outside of work, she creates educational videos on YouTube (@ggnot2) about R and data science, and is an organizer for R-Ladies Ottawa. Melissa is an Accredited Associate Statistician, and received her M. Sc. in Statistics from Carleton University and has a B. Sc. H. in Mathematics and Computing Systems from Trent University.

## Title: Translating R for Data Science into Portuguese: A Community-Led Initiative
**Code:** PAR-002
**Session type:** Breakout Session

**Abstract:**
How can open-source collaboration help make data science more accessible and expand Posit’s global impact? The book ""R for Data Science"" by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund is a key resource for learning R and the tidyverse. In a collaborative effort, volunteers from the R community translated the second edition into Brazilian Portuguese, making it freely available online. This talk explores the translation journey, the challenges of adapting technical content, and key lessons learned to support future translation teams.

**Speaker name:** Beatriz Milz
**Job title:** Post doc / Community organizer / Software peer review editor
**Company:** UFABC / R-Ladies São Paulo / rOpensci
**Bio:**
Beatriz Milz holds a PhD in Environmental Science (USP) and is a postdoctoral researcher at UFABC. Since 2018 she has co-organized R-Ladies São Paulo and earned GitHub Star recognition. She led the community translation of “R for Data Science” (2nd ed.) into Brazilian Portuguese and contributes as a software peer-review editor and dev-guide translator at rOpenSci.

## Title: Representation Matters: An Atlas of Inspiring Hispanic/Latinx Scientists
**Code:** PAR-002
**Session type:** Breakout Session

**Abstract:**
Mentorship and representation shape careers in STEM. When a mentee asked if I knew any Cuban scientists, I couldn’t name one. This led me to Dr. Tina Termini’s List of 100 Inspiring Latinx/Hispanic Scientists. Inspired, we co-hosted her on From where does it STEM? and collaborated to expand her list into an Atlas of Inspiring Hispanic/Latinx Scientists. From February to July 2024, our team contacted 400+ scientists, launching the Atlas on September 1. Now, I’m developing an R Shiny dashboard to enhance accessibility. This initiative highlights how data science, community, and mentorship can drive representation in STEM.

**Speaker name:** JP Flores
**Job title:** PhD Candidate
**Company:** UNC Chapel Hill
**Bio:**
JP is a 4th year PhD candidate in Bioinformatics & Computational Biology at UNC Chapel Hill studying 3D chromatin structure and gene regulation. At UNC, he is also pursuing a Graduate Certificate in Innovation for the Public Good. Originally from Los Angeles, CA, he is a HHMI Gilliam Fellow, an AIBS Emerging Public Policy Fellow, an ASHG Human Genetics Scholar Initiative awardee, and a UCLA CDLS Early Career Fellow. He is the Founder and Host of the From where does it STEM? podcast, which won a Spotify Next Wave Award in 2021 and was a Spotify Podcast of the Week in May 2024.

In the first half of 2024, he completed a 6 month internship in the NIH Office of Science Policy under the mentorship of Drs. Alissa Meister, Jessica Tucker, and Lyric Jorgensen. He is a co-lead of SCOPE (Science Communication, Outreach, and Public Engagement), a program dedicated to highlighting innovative science communication and public engagement projects.

He is passionate about bridging science and society and empowering others, especially those from minoritized and marginalized backgrounds.

## Title: rOpenSci Champions: Building Communities of Open-Source Leaders
**Code:** PAR-002
**Session type:** Breakout Session

**Abstract:**
rOpenSci's Champions program is designed to build a diverse, inclusive, and sustainable community of scientific R developers.  We identify emerging leaders in open science from underrepresented communities globally.  We link them together with each other and with mentors who are experienced software engineers and teachers.  In a months long program of skill and project building, they create, contribute to and review R packages.  Then they bring those approaches back to their local scientific communities. In this talk, I will discuss the methods and accomplishments of the Champions program, and discuss how we can use this approach to build sustainable communities to maintain open-source software.

**Speaker name:** Noam Ross
**Job title:** Executive Director
**Company:** rOpenSci
**Bio:**
Hello! I'm Executive Director of rOpenSci, a group that builds tools, infrastructure, and community so that R and science are more open and inclusive. We're excited about supporting R developers through peer review, mentorship, new platforms, and long-term maintenance. I also study and work in forecasting emerging diseases. I like splines, Bayesian methods, and simple tools to help make scientific insights available to policymakers and implementers.  Find me to chat about any of these things!"
Breakout Session,LLMs with R and Python,"## Title: AI Coding Assistants: Hype, Help, or Hindrance?
**Code:** PAR-001
**Session type:** Breakout Session

**Abstract:**
AI coding assistants like ChatGPT, GitHub Copilot, and Codeium promise to revolutionize our coding workflows—but how useful are they in practice? Are they our new overlords here to take our jobs? Or just a passing gimmick? I think the reality lies somewhere in between, and that understanding these tools is key to staying relevant in today’s rapidly evolving data science ecosystem.
<br><br>
In this talk, I'll show how I’ve used these AI tools in RStudio, Positron, and VS Code to speed up both my advanced R workflows as well as my learning experience as an intermediate Python programmer, providing examples, pitfalls, and best practices.

**Speaker name:** Rebecca Barter
**Job title:** Research Assistant Professor
**Company:** University of Utah
**Bio:**
Rebecca is a data scientist and educator with a passion for teaching data science and uncovering the hidden patterns in healthcare data. Originally from Australia, Rebecca received her PhD in Statistics from UC Berkeley in 2019, during which time she co-authored a book and shared many helpful tips and resources on her blog, www.rebeccabarter.com. When she’s not working with data, you can find her hiking, climbing, or making pottery.

## Title: AskRADS: An AI Recommendation Agent for Maximizing the ROI of Data Science Collaborations
**Code:** PAR-001
**Session type:** Breakout Session

**Abstract:**
Blockers to crucial data-driven decisions can often be a challenge.  To address this, we established RADS, the Regeneron Analysts and Data Scientists, as a Community of Practice for exchanging strategies on eliminating these obstacles. RADS has grown to nearly 500 members, creating a new challenge: avoiding redundancy and helping non-RADS colleagues find the right experts. To solve this, we developed AskRADS, an AI agent on Posit Connect that provides recommendations based on discussions, experts, and relevant resources. It uses R, Shiny for Python, FastAPI, LangGraph, Neo4j GraphRAG, and MySQL. This talk will cover its architecture, AI search solutions, and optimization techniques.

**Speaker name:** Regis A. James
**Job title:** Associate Director of AI Data Science, Strategist, and Community of Practice Leader
**Company:** Regeneron Pharmaceuticals
**Bio:**
I build AI systems that we teach to make data-driven decision recommendations for humans.

At Regeneron Pharmaceuticals, a world-class developer of therapeutic biologics, I work as a full-stack data scientist to make medicine and optimize clinical trial logistics by collaborating with colleagues to bring structure to and extract meaning from biological data, helping illuminate nonobvious underlying relationships.  I also created and lead a vibrant data science community of practice, comprising hundreds of my colleagues across the company.

## Title: Is that LLM feature any good?
**Code:** PAR-001
**Session type:** Breakout Session

**Abstract:**
The ellmer package has enabled R users to build all sorts of powerful LLM-enabled tools. How do you test these features, though? How do you know whether a change to your prompt made any difference, or if a much cheaper model would work just as well for your users? This talk introduces an R port of Inspect, a Python framework for LLM evaluation that has been widely adopted by both LLM developers and tool builders. Attendees will learn about the process of—and importance of—evaluating LLM-enabled apps empirically.

**Speaker name:** Simon P. Couch
**Job title:** Software Engineer
**Company:** Posit, PBC
**Bio:**
Simon Couch is a software engineer at Posit PBC where he works on open source statistical software. With an academic background in statistics and sociology, Simon believes that principled tooling has a profound impact on our ability to think rigorously about data. He authors and maintains a number of R packages and blogs about the process at simonpcouch.com. 

## Title: Trust, but Verify: Lessons from Deploying LLMs in a Large Health System
**Code:** PAR-001
**Session type:** Breakout Session

**Abstract:**
Large language models (LLMs) are transforming how data practitioners work with unstructured text data. However, in high-stakes domains like medicine, we need to ensure that “hallucinated” clinical details don’t mislead clinicians. 
<br><br>
This talk will present a framework for evaluating and monitoring LLM systems, drawing from a real-world deployment at Stanford Health Care. We will describe how we built and assessed an LLM-powered system for real-time, automated chart abstraction within patients’ electronic health records, focusing on methods for measuring accuracy, consistency, and safety. Additionally, we will discuss how open-source tools like Chatlas and Quarto powered the work across our team’s combined Python- and R-based workflows.

**Speaker name:** Timothy Keyes
**Job title:** Data Scientist
**Company:** Stanford Health Care
**Bio:**
Timothy Keyes is a Data Scientist at Stanford Health Care, where he deploys large language models in clinical workflows and builds systems to track their real-world performance. He focuses on making AI tools accurate, reliable, and useful for health care teams. He holds a PhD from Stanford and is an MD/PhD candidate in its Medical Scientist Training Program."
Breakout Session,Learning by Doing,"## Title: Positron for Babies
**Code:** PAR-012
**Session type:** Breakout Session

**Abstract:**
Data science is full of complex topics—Bayesian statistics, neural networks, databases, and more. Now, imagine teaching one of these to a baby. What would you say? How would you say it? This exercise highlights the power of simplification: anyone can teach, and anyone can learn. Breaking down complexity makes data science accessible, impactful, and fosters greater creativity and flexibility. In this talk, I’ll share my approach to simplifying data science education with a playful demonstration using Posit’s new IDE, Positron, as the focus!

**Speaker name:** Ryan Johnson
**Job title:** Data Science Advisor
**Company:** Posit, PBC
**Bio:**
Ryan is a Data Science Advisor at Posit with a background in Microbiology and Bioinformatics. He obtained his Ph.D. from the Uniformed Services University in Maryland and did his postdoctoral training at the National Human Genome Research Institute, NIH. In his current role, Ryan serves as a data science advocate and hosts workshops and webinars for teams across the globe.

## Title: Teaching Data Sharing through R Data Packages
**Code:** PAR-012
**Session type:** Breakout Session

**Abstract:**
Data science courses tend to teach students reproducible workflows.  However, the origin of the data used in these workflows and definitions of the variables used are often not emphasized.  This talk addresses this gap by focusing on how to teach students effective data sharing through the creation of R data packages.  We’ll explore how to leverage key packages, such as devtools and usethis, and will demonstrate how to guide students in generating appropriate documentation through ReadMes, help files, and vignettes.  Furthermore, we’ll discuss common pitfalls encountered when first learning to create R packages and will propose how to structure a project assignment where an R data package serves as the primary deliverable.

**Speaker name:** Kelly McConville
**Job title:** Associate Professor/Director
**Company:** Bucknell University
**Bio:**
Kelly McConville recently joined Bucknell University as the inaugural Director for the Dominguez Center for Data Science.  Before that she was the co-Director of Undergraduate Studies for the Department of Statistics at Harvard University.  Her research explores how to combine big data sources with complex survey data using machine learning models and involves active collaborations with the US Bureau of Labor Statistics and the US Forest Service.  She is a Fellow of the American Statistical Association.

Kelly has taught across the data science curriculum.  Learning from data is tough and yet she truly loves introducing students to coding in R and helping them develop their data problem-solving skills.  To support a culture of open research and instill its importance in her students, she has co-authored three R packages (mase, pdxTrees, and saeczi) with several amazing undergraduate collaborators.

## Title: From Solo to Social: Making Coding a Collaborative Adventure
**Code:** PAR-012
**Session type:** Breakout Session

**Abstract:**
What if coding were not an exclusive skill but an accessible adventure? Through community-driven, project-based learning, I transform data science education into an inclusive journey. My approach builds trust by meeting participants where they are, using familiar tools and relevant datasets. Through targeted workshops, and collaborative hackathons, I break down complex coding concepts into digestible applications for global audiences.
<br><br>
By reimagining how we teach technical skills, I'm not just delivering education—I'm fostering a movement that makes data science accessible to all. Join me to discover how we can democratize coding and create pathways for everyone to become active members of the data science community.

**Speaker name:** Allissa Dillman
**Job title:** Founder/CEO
**Company:** BioData Sage
**Bio:**
Dr. Allissa Dillman is the Founder and CEO of BioData Sage, co-PI of the NIH Common Fund Data Ecosystem Training Center, and adjunct faculty at Montgomery College. She has led national training initiatives, organized hackathons and workshops, built learning platforms, and expanded access to data science skills across academic, government, and nonprofit sectors.

## Title: On teaching adults to code
**Code:** PAR-012
**Session type:** Breakout Session

**Abstract:**
Working with code can be deeply rewarding, but learning to code can be daunting; similarly, changing the code habits of a team may feel monstrous. For the last three years, the Posit Academy team has been working to teach adults to code in a way that sticks with individual learners, scales within organizations, and leaves individuals with the ability to adapt in an evolving technological landscape. In this talk I will share some lessons we’ve learned, speak to the importance of communities of practice, and share some thoughts on where AI fits -- and doesn't - in learning.

**Speaker name:** Kristin Bott
**Job title:** Manager, Data Science Mentors, Posit Academy
**Company:** Posit, PBC
**Bio:**
Kristin manages the Posit Academy data science mentor team and supports learners as they build skills in both code and collaboration. With a background in natural science, teaching, and research, Kristin is interested in making technical topics accessible through the power of learning communities, ultimately empowering individuals to do great work."
Breakout Session,Machine Learning and Statistical Modelling,"## Title: Building a Real-Time COVID-19 Surveillance System with R: Lessons from the COVID Symptom Study Sweden
**Code:** PAR-013
**Session type:** Breakout Session

**Abstract:**
During the COVID-19 pandemic, the COVID Symptom Study Sweden collected over 20 million daily health reports from more than 200K participants. This talk demonstrates how R served as the backbone for transforming this massive dataset into actionable public health insights. I'll showcase our analytics pipeline built entirely in R, from processing raw data to developing an interactive Shiny dashboard for real-time COVID-19 surveillance. The presentation covers predictive modeling for prevalence and hospital admissions estimates and the creation of our 'covidsymptom' R package. Through practical examples, I'll share key learnings about handling large-scale health data and creating data products with R during a public health emergency.

**Speaker name:** Hugo Fitipaldi
**Job title:** Postdoctoral Research Fellow
**Company:** Lund University
**Bio:**
Hugo Fitipaldi is a postdoctoral fellow at Lund University, Sweden, specializing in clinical data science. With a PhD in Genetic Epidemiology, Hugo develops advanced computational methods to analyze complex biomedical data, from multi-omics to longitudinal clinical records. His research employs multimodal machine learning approaches to characterize molecular disease subtypes, identify and validate predictive biomarkers, and advance precision medicine strategies for cardiometabolic disorders.

## Title: An R package to run millions of models
**Code:** PAR-013
**Session type:** Breakout Session

**Abstract:**
Would koalas prefer to live on the East Coast or West Coast of the US? 
<br><br>
Answering complex questions like this requires robust and scalable technology. Enter EcoCommons, a cutting-edge platform built on an R package that’s scientifically rigorous and designed for scale. EcoCommons efficiently runs millions of models to help researchers, governments, and NGOs make data-driven decisions. Whether it's predicting habitat loss, optimising conservation strategies, or advising policy, this platform turns R into a powerhouse for real-world impact—all while building a thriving community of practice. In this talk, we’ll explore the challenges of running R at scale, lessons learned, and how our community is shaping the future of modelling.

**Speaker name:** Jenna Wraith
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: Precision Medicine for All: Using Tidymodels to Validate PRS in Brazil
**Code:** PAR-013
**Session type:** Breakout Session

**Abstract:**
Polygenic risk scores (PRS) are a powerful way to measure someone’s risk for common diseases, such as diabetes, cardiovascular disease, and cancer. However, most PRS are developed using data from European populations, making it challenging to generalize results to other ancestries. In this talk, I’ll show how I used tidymodels tools—like yardstick, recipes, and workflows—to calculate metrics and validate a breast cancer PRS in the highly admixed Brazilian population. You will learn how to leverage tidymodels to make precision medicine more inclusive.

**Speaker name:** Flávia E. Rius
**Job title:** Data Scientist / Researcher
**Company:** Mendelics / University of São Paulo
**Bio:**
Flávia E. Rius is a data scientist and bioinformatician interested in evaluating Polygenic Risk Scores (PRS) in the highly admixed Brazilian population. She works at Mendelics, the largest company specialized in genetic diagnostic tests in Brazil, and conducts postdoctoral research at the University of São Paulo. She is also passionate about solving problems on diverse topics within the realm of R and bioinformatics, which she accomplishes through mentoring sessions and occasional freelance jobs.

## Title: Demystifying MLOps with Vetiver
**Code:** PAR-013
**Session type:** Breakout Session

**Abstract:**
MLOps is the process of setting up a Machine Learning lifecycle, including model training, deployment and monitoring. It is a complex topic which brings together an understanding of data processing, modelling and cloud architecture. It is therefore not surprising that many newcomers (myself included) can feel intimidated by the subject. In this talk I will draw on my experience as an organiser of local data science meetups. I will go into how MLOps is often presented within the data science community, how it could be made more accessible to students and beginners, and my current process for teaching MLOps in R and Python using my favourite package, vetiver. In summary: no, you do not have to be an expert in AWS or Azure to get started!

**Speaker name:** Myles Mitchell
**Job title:** Principal Data Scientist
**Company:** Jumping Rivers
**Bio:**
NA"
Breakout Session,Multilingual Data Science,"## Title: Building Multilingual Data Science Teams
**Code:** PAR-015
**Session type:** Breakout Session

**Abstract:**
For much of my career, I have seen data science teams make the critical decision of deciding whether they are going to be an “R shop” or a “Python shop”.  Doing both seemed impossible. I argue that this has changed drastically, as we have built out an effective multilingual data science team at Ketchbrook, thanks to polars/dplyr, gt/great-tables, ggplot2/plotnine, arrow, duckdb, Quarto, etc. I would like to provide a walk through of our journey to developing a multilingual data science team, lessons learned, and best practices.

**Speaker name:** Michael Thomas
**Job title:** Chief Data Scientist
**Company:** Ketchbrook Analytics
**Bio:**
Michael Thomas is the Chief Data Scientist at Ketchbrook Analytics, a data science consulting firm based out of Hartford, CT.  He holds a B.S. in Accounting and Mathematics from Stonehill College, and an M.S. in Business Intelligence & Analytics from Saint Joseph’s University.  He leads Ketchbrook's data science consulting and software-as-a-service practices.  He is also the co-host of the RWeekly Highlights Podcast with Eric Nantz.

## Title: Polyglot Data Science: Why and How to Combine R and Python
**Code:** PAR-015
**Session type:** Breakout Session

**Abstract:**
Doing everything in one language is convenient but not always possible. For example, your Python app might need an algorithm only available as an R package. Or your R analysis might need to fit into a Python pipeline. What do you do? You take a polyglot approach! Many data scientists hesitate to explore beyond their main language, but combining R and Python can be powerful. In my talk, I’ll explain why polyglot data science is beneficial and address common concerns. Then, I’ll show you how to make it happen using tools like Quarto, Positron, Reticulate, and the Unix command line. By the end, you’ll gain a fresh perspective and practical ideas to start.

**Speaker name:** Jeroen Janssens
**Job title:** 
**Company:** Posit
**Bio:**
NA

## Title: When R Met Python: A Meet Cute on Posit Connect
**Code:** PAR-015
**Session type:** Breakout Session

**Abstract:**
Data teams often leverage multiple programming languages—driven by a multitude of reasons, be it task-specific requirements or personal preference. In this talk, I'll share how we enabled our developer base to build in the language of their choice, and how we leverage Posit Connect to unify them. By exposing core functionality as APIs using R’s plumber and Python’s FastAPI packages, and building parity in internal packages for both languages, we created a shared toolkit that streamlines workflows and fosters collaboration. Join me to explore our journey in breaking down language barriers and empowering data innovation.

**Speaker name:** Blake Abbenante
**Job title:** Director, Analytics & Data Science
**Company:** Suffolk Construction
**Bio:**
Blake is a seasoned leader in data analytics and business intelligence, currently serving as the Director of Analytics & Data Science at Suffolk Construction. With over two decades of experience, he has successfully driven data strategy, innovation, and AI adoption across industries, including construction, healthcare, real estate, and technology. His expertise spans data-driven decision-making, predictive modeling, machine learning applications, and business intelligence solutions that enhance operational efficiency and profitability.

## Title: R & Python playing nice, in production
**Code:** PAR-015
**Session type:** Breakout Session

**Abstract:**
Hi, I’m Claudia Peñaloza, a Data Scientist at Continental Tires, where going data-driven can be an adventure.
<br>What started as a proof of concept a few years ago, evolved into Conti’s first-ever Predictive Machine Learning Model for R&D! 
<br>A baby, a wedding, two lateral moves, and three hires later, our team had also evolved… from mostly R to mostly Python developers. 
<br>Rewriting 1000+ commits? No thanks. Instead, we got R and Python to play nice. With Renv, Poetry, and Docker, we keep things reproducible, portable, and deployable on various ML-Ops platforms.
<br>The takeaway? With the right tools, teams can mix and match languages, leveraging the best in each, and still build solid, scalable solutions.

**Speaker name:** Claudia Penaloza
**Job title:** Data Scientist
**Company:** Continental Tires
**Bio:**
Claudia Penaloza is a Data Scientist at Continental Tires, where she has spent seven years developing and industrializing data-driven, statistical, and machine learning solutions across the company (R&D, Manufacturing, Market Intelligence, Controlling, etc.). She holds a Ph.D. in Quantitative Ecology, with a background in endangered species population modeling and simulation research. A self-taught R user, Claudia turned to R out of desperation to escape regenerating plots through hundreds of manual clicks in Excel after every simulation update. Her passion for efficient, reproducible analysis has only grown since. A decades-long competitive cyclist, she’s proud to bring her analytical skills to her favorite tire company."
Breakout Session,Pedagogy as Software,"## Title: Teaching data visualization with R entirely in Quarto
**Code:** PAR-016
**Session type:** Breakout Session

**Abstract:**
When teaching a programming course, we may want to employ several different modes of content delivery. First, slides. (And it should be easy to integrate code and code output into them.) Second, practical exercises, where students can try out programming concepts in a guided manner. Third, an in-class live programming environment, to ad-lib during lectures. Fourth, a framework for graded assignments. Fifth, a class website. All of these components can be created with Quarto and webR. I will explain how I used these technologies for my data visualization class at UT Austin, covering how the different components work, what issues I encountered, and what I think best practices are if you want to create a similar course yourself.

**Speaker name:** Claus Wilke
**Job title:** Professor
**Company:** The University of Texas at Austin
**Bio:**
Claus Wilke is a computational biologist and data scientist at The University of Texas at Austin, running a research lab that studies protein and peptide biochemistry. Claus is also the author of the book ""Fundamentals of Data Visualization,"" and he teaches data visualization at The University of Texas, both at the undergraduate and at the graduate level. He is an avid user of and regular contributor to the R ecosystem. He has authored several popular R packages used for data visualization, such as cowplot, ggridges, and ggtext.

## Title: ChalkTalk: Globalizing Data Science Education with AI-generated Videos
**Code:** PAR-016
**Session type:** Breakout Session

**Abstract:**
We present ChalkTalk, an open-source tool that converts Quarto documents into engaging educational videos with AI-powered voices and avatars. By adding simple text-to-speech (TTS) and text-to-video (TTV) attributes to markdown files, educators can automatically generate multilingual video content while maintaining the reproducibility benefits of Quarto. At The GRAPH Courses, where we've trained over 3,000 learners globally, we are testing out this tool to scale our video content creation. We'll demonstrate its integration with Quarto and present preliminary findings from our A/B testing with students.

**Speaker name:** Kenechukwu Nwosu
**Job title:** Curriculum Director
**Company:** TheGraphCourses.org
**Bio:**
[Kene David Nwosu](https://www.linkedin.com/in/kene-david-nwosu/) is an epidemiologist (PhDc) at the University of Geneva in Switzerland, and curriculum director of [The GRAPH Courses](https://thegraphcourses.org), a WHO-supported non-profit providing open-source R and Python training to health and life-science professionals across 50+ countries. Originally from Nigeria, Kene is passionate about expanding global access to data and AI literacy. With GRAPH , he is developing [ChalkTalk](https://github.com/the-graph-courses/chalktalk), an open-source tool that uses LLMs to convert textbooks, papers, and plain-text lessons into adaptive, multilingual teaching videos for personalized learning at scale.

## Title: Empowering Learners with WebR, Pyodide, and Quarto
**Code:** PAR-016
**Session type:** Breakout Session

**Abstract:**
WebR, Pyodide, and Quarto are powerful technologies that let you run code exercises in the Web browser. Because of this, WebR exercises can be integrated into data science lessons within RevealJS slides and Quarto websites. In this talk, I want to emphasize some considerations for using WebR/Pyodide for active learning in the classroom. 
<br><br>
Careful exercise design with WebR/Pyodide can make the difference between empowering learners and demotivating them. With our R-Bootcamp and other exercises as examples, I show scaffolding methods for teaching data science concepts gradually, as well as other design considerations. I'll finish up with showing you how to set up WebR up in your slides and websites for your Data Science Learners.

**Speaker name:** Ted Laderas
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: Leveraging LLMs for student feedback in introductory data science courses
**Code:** PAR-016
**Session type:** Breakout Session

**Abstract:**
A considerable recent challenge for learners and teachers of data science courses is the proliferation of the use of LLM-based tools in generating answers. In this talk, I will introduce an R package that leverages LLMs to produce immediate feedback on student work to motivate them to give it a try themselves first. I will discuss technical details of augmenting models with course materials, backend and user interface decisions, challenges around evaluations that are not done correctly by the LLM, and student feedback from the first set of users. Finally, I will touch on incorporating this tool into low-stakes assessment and ethical considerations for the formal assessment structure of the course relying on LLMs.

**Speaker name:** Mine Cetinkaya-Rundel
**Job title:** Professor + Developer Educator
**Company:** Posit
**Bio:**
<p><a href=""http://mine-cr.com/"" target=""_blank""><strong>Dr. Mine Çetinkaya-Rundel</strong></a> (she/her) is Professor of the Practice at Duke University and Developer Educator at Posit. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine works on integrating computation into the undergraduate statistics curriculum, using reproducible research methodologies and analysis of real and complex datasets. Mine works on the OpenIntro project, whose mission is to make educational products that are free, transparent, and lower barriers to education. As part of this project she co-authored four open-source introductory statistics textbooks. She is also the creator and maintainer of datasciencebox.org and she teaches the popular Statistics with R MOOC on Coursera. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for Excellence in Teaching Introductory Statistics.</p>"
Breakout Session,Positron,"## Title: Outgrowing Your Laptop with Positron
**Code:** PAR-017
**Session type:** Breakout Session

**Abstract:**
Ever run out of memory or time when crunching data, making a visualization, or training a model? As computational demands and data sizes grow, many practitioners find their laptops behaving more like cranky toddlers than high-performance machines. In this talk, we’ll demo how the Positron IDE helps you scale your development without losing your sanity or your data. You’ll learn how Positron can integrate into different setups and see how lazy-evaluated libraries like Ibis can manage data too big for memory. Whether you're building AI models, running complex simulations, or working with large-scale datasets, you’ll walk away with techniques for doing it better with Positron.

**Speaker name:** Austin Dickey
**Job title:** Senior Software Engineer
**Company:** Posit, PBC
**Bio:**
Austin is a positive Positron developer at Posit. After years creating data science models, he fell in love with the tools that speed up practicing and deploying data science. Now he's on a mission to make the life of every data scientist a little bit better.

## Title: Exploring Datasets in Positron
**Code:** PAR-017
**Session type:** Breakout Session

**Abstract:**
Inspecting raw data in data frames and tables can be a critical tool in the data preparation, tidying, and feature engineering process. In Positron, we made it a priority to design a modern Data Explorer component that works well for both large and small datasets. In this talk, I will discuss the design of the Data Explorer UI and its backends for Python, R, and DuckDB, and how we made it work smoothly with massive datasets having millions of rows or thousands of columns. Additionally, I will discuss the sorting, filtering, search, and statistical data visualization capabilities that we have added to help make users more productive.

**Speaker name:** Wes McKinney
**Job title:** Principal Architect
**Company:** Posit
**Bio:**
Wes McKinney is an as an open source software developer and entrepreneur focusing on data processing tools and systems. He created the Python pandas and Ibis projects, co-created Apache Arrow, and co-founded Voltron Data. He is a Member of the Apache Software Foundation and also a project PMC member for Apache Parquet. He is currently a Principal Architect at Posit PBC where he works on Positron and other Python-related initiatives.

## Title: Tips & tricks from the maintainers of Positron
**Code:** PAR-017
**Session type:** Breakout Session

**Abstract:**
Positron is Posit’s next-generation IDE for data science. Finding your groove in a new IDE takes time, so we’ve got some tips and tricks to help you feel more at home in Positron!
<br><br>
We’ll cover key navigation concepts, helpful features for different workflows, and configuration settings for a pleasant IDE experience. Plus, we’ll show you how to explore what Positron is doing under the hood – so you can understand it more deeply and solve problems with confidence.
<br><br>
Whether you’re just getting started or already using Positron, these tips will help you settle into your data science workflow and get the most out of everything Positron has to offer.

**Speaker name:** Melissa Oldham Barca
**Job title:** Senior Software Engineer
**Company:** Posit, PBC.
**Bio:**
NA

## Title: Tips & tricks from the maintainers of Positron
**Code:** PAR-017
**Session type:** Breakout Session

**Abstract:**
Positron is Posit’s next-generation IDE for data science. Finding your groove in a new IDE takes time, so we’ve got some tips and tricks to help you feel more at home in Positron!
<br><br>
We’ll cover key navigation concepts, helpful features for different workflows, and configuration settings for a pleasant IDE experience. Plus, we’ll show you how to explore what Positron is doing under the hood – so you can understand it more deeply and solve problems with confidence.
<br><br>
Whether you’re just getting started or already using Positron, these tips will help you settle into your data science workflow and get the most out of everything Positron has to offer.

**Speaker name:** Sharon Wang
**Job title:** Senior Software Engineer
**Company:** Posit
**Bio:**
NA

## Title: IDE-ntity Crisis: Choosing the Right Tool for Me
**Code:** PAR-017
**Session type:** Breakout Session

**Abstract:**
Data practitioners have more IDE choices than ever, but not all are built for the same purpose. JupyterLab prioritizes a notebook-first experience, while VS Code focuses on software engineering with extensible features. Others, like Positron, are designed specifically for data scientists, streamlining workflows and boosting productivity.
<br><br>
Understanding these trade-offs helps you find the best fit. By the end of the session, you'll have a clear framework for choosing the right IDE for your data science and analytics tasks.

**Speaker name:** Isabel Zimmerman
**Job title:** Software Engineer
**Company:** 
**Bio:**
<p><u><a href=""https://www.isabelizimm.me/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Isabel Zimmerman</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;"">(she/her) is a software engineer at Posit, PBC. As part of her job at Posit, she builds and maintains MLOps Python packages such as vetiver and pins. She has a background as a software engineer/data scientist working with data and models in cloud environments.</span></p>"
Breakout Session,Put It In Production,"## Title: Lift Off! Building REST APIs that Fly
**Code:** PAR-018
**Session type:** Breakout Session

**Abstract:**
Picture the scene: you've successfully deployed your ML model as a plumber API into production. Your company loves it! One team uses the API's predictions as an input to their own ML model. Another team displays the predictions in an internal Shiny app. But once adoption reaches a certain point, your API's performance starts to degrade. What can you do to help your service maintain high performance in the face of high demand? In this talk, we'll show some strategies for taking your API performance to the next level. Using two R packages, {yyjsonr} and {mirai}, we can augment our API with faster JSON processing and better responsiveness through asynchronous computing, allowing our services to do great things at scale at no additional cost.

**Speaker name:** Joe Kirincic
**Job title:** Principal Data Scientist
**Company:** 
**Bio:**
Joe Kirincic is a senior data scientist at Medical Mutual. Growing up, he kept a small zoo of 275 animals. After the zoo disbanded, he studied philosophy and math at Ohio Wesleyan University. He stumbled into the data space through a series of happy accidents. In prior roles, he worked as a data analyst and a data engineer. His interests include (but are not limited to) representation learning and simulation studies. Outside of the data space, Joe is a member of the sketch comedy group, Kidney+.

## Title: Building Governable ML Models with R
**Code:** PAR-018
**Session type:** Breakout Session

**Abstract:**
For a model to provide value in production, it must be fit for purpose and deployable into the MLOps environment. We know that R provides a host of tools and packages for building good models; this talk will demonstrate one way we've had success assembling R and R-packaging features to provide a stable foundation for model deployment and governance after production. Those attending this talk will learn how, by centering model development on packages, writing tests as we go, creating intuitive S3 methods, and more, we can build modularized, testable code that separates operations from modeling, making our models easier to deploy, monitor, and update, whether the environment incorporates CI/CD, model registries, schedulers, or anything else.

**Speaker name:** Tom Shafer
**Job title:** Principal Data Scientist
**Company:** Elder Research, Inc.
**Bio:**
Tom Shafer works as a Principal Data Scientist at Elder Research, where he leads the data scientists in the company’s Commercial consulting practice. He is especially interested in Bayesian modeling and building interpretable ML systems, enjoys building software tools, and works regularly in both the R and Python ecosystems. He also runs an Elder Research Innovation Lab, developing new tools and techniques. Prior to joining Elder Research, Tom completed a PhD in Physics; he lives in Raleigh, NC.

## Title: Producethis: Automate project and deployment setup
**Code:** PAR-018
**Session type:** Breakout Session

**Abstract:**
There is a common misconception that R code cannot (or shouldn't) be put in production. While we disagree with this idea we also acknowledge that there are missing pieces when in education and tooling around R code deployment. In this talk I will present some of our work within tooling in the form of a package called “producethis”. producethis is a package that helps you streamline and organise your R project code. It provides an opinionated take on code organisation that makes it easier to test and deploy code. Further, it pushes the idea of git-backed deployment which eases collaboration and helps roll back deployments if things go wrong. We hope that producethis will help R users have their code reach an even larger audience.

**Speaker name:** Thomas Lin Lin Pedersen
**Job title:** Software Engineer
**Company:** Posit
**Bio:**
Thomas Lin Pedersen is a software engineer in the Tidyverse team at Posit. He spends most of his time taking care of the graphics stack in R from maintaining high-level packages such as ggplot2 and patchwork, all the way down to developing and maintaining graphics devices like ragg and svglite.

## Title: Oops! I accidentally made a production dashboard
**Code:** PAR-018
**Session type:** Breakout Session

**Abstract:**
As data scientists we love making decisions with data. But we also don’t always do this with our own work. Ever wonder if that dashboard you are about to spend hours updating from line charts to 3D pie charts is actually being used? With usage metrics it’s easy for you to see, analyze, and show just how much traction your app is getting. Not only does this let you decide where to prioritize your efforts, it can help you demonstrate the impact you have on your business. This talk will explore how to be data-driven with your own work and tools we have for maintaining our work when it becomes important.

**Speaker name:** Jonathan Keane
**Job title:** Senior Engineering Manager
**Company:** Posit, PBC
**Bio:**
NA"
Breakout Session,Quarto,"## Title: surveydown: A Markdown-Based Platform for Interactive and Reproducible Surveys Using Quarto and Shiny
**Code:** PAR-019
**Session type:** Breakout Session

**Abstract:**
This talk introduces the surveydown R package and survey platform, which leverages the Quarto publication system and R shiny web framework to create reproducible and interactive surveys. While most survey platforms rely on graphical interfaces or spreadsheets to define survey content, surveydown uses plain text (markdown and R code chunks), enabling version control and collaboration via tools like GitHub. It supports complex features like conditional skip logic, dynamic questions, and complex randomization as well as a diverse set of question types and formatting options. The open-source package gives researchers full control over survey implementation and data storage, with reproducible workflows that integrate with R data analysis.

**Speaker name:** John Paul Helveston
**Job title:** Associate Professor
**Company:** George Washington University
**Bio:**
John Paul (JP) is an Associate Professor at George Washington University in the Department of Engineering Management and Systems Engineering. His research focuses on understanding how consumer preferences, market dynamics, and policy affect the emergence and adoption of low-carbon technologies, such as electric vehicles and renewable energy technologies. He also studies the critical relationship between the US and China in developing and mass producing these technologies. He has expertise in discrete choice modeling, conjoint analysis, survey design, exploratory data analysis, interview-based research methods, the R programming language, China, and the global electric vehicle industry. He speaks fluent Mandarin Chinese and has conducted extensive fieldwork in China. John holds a Ph.D. and M.S. in Engineering and Public Policy from Carnegie Mellon University and a B.S. in Engineering Science and Mechanics (ESM) from Virginia Tech.

## Title: Using Quarto to Improve Formatting and Automate the Generation of Hundreds of Reports
**Code:** PAR-019
**Session type:** Breakout Session

**Abstract:**
This presentation showcases how KS&R’s Decision Sciences and Innovation (DSI) team modernized a legacy reporting pipeline to automate and scale custom survey report generation. Using tidyverse and Quarto, the team produced hundreds of personalized PDFs weekly over three months. Hosted on GitHub, the project integrated version control and streamlined collaboration while documentation ensured easy onboarding and adaptability. Attendees will gain insights into automating report workflows, overcoming implementation challenges, integrating custom formatting and fostering collaboration using tidyverse, Quarto, and GitHub.

**Speaker name:** Keaton Wilson
**Job title:** Solutions Developer
**Company:** KS&R
**Bio:**
Keaton Wilson is a seasoned Data Scientist with over a decade of experience, specializing in transforming complex data into actionable insights and compelling narratives. With a strong foundation in research, including advanced degrees and postdoctoral training, Keaton is adept at using a blend of statistical models and machine learning techniques to drive strategic decisions in diverse sectors.

Currently working as a Solutions Developer at KS&R, Keaton excels in environments that challenge his range of skills—from data engineering to visualization and development. His work has spanned client and collaborator types, from Fortune 500 companies to federal agencies, has consistently advanced knowledge and sparked further inquiry, establishing him as a leader in the field.

## Title: Instant Impact: Developing {docorator} to Simplify R Adoption for Teams
**Code:** PAR-019
**Session type:** Breakout Session

**Abstract:**
Although R supports comprehensive analysis workflows, creating polished, production-ready PDFs directly from R remained a challenge for our pharma teams. With teams facing looming deadlines, our R enablement team swiftly created {docorator}—an open-source R package that transforms R-based tables and figures into production-level PDFs. By adorning results with “decorations” like headers, footers, and page numbers, {docorator} produces seamless, polished documents. Powered by Quarto, it also auto-sizes {gt} tables for user ease. Attendees will learn how {docorator} became the missing piece in GSK’s R workflows and learn how focusing on quick, simple solutions can have a lasting impact.

**Speaker name:** Becca Krouse
**Job title:** Data Science Leader
**Company:** GSK
**Bio:**
Becca Krouse is a data scientist in GSK’s Data Science Innovation and Engineering team where she focuses on enabling users across Biostatistics. A biostatistician by training, she has experience spanning 15 years in the field of clinical research and specializes in developing R-based tools.

## Title: Beyond the Basics: Expanding Quarto's Capabilities with Lua
**Code:** PAR-019
**Session type:** Breakout Session

**Abstract:**
Are you familiar with Quarto and eager to push its boundaries? This session is for those ready to explore the power of Lua for customization. Whether you're a novice implementing simple Lua filters or a seasoned developer seeking inspiration for Quarto Extensions, this talk offers valuable insights into Pandoc's and Quarto's Lua features.
<br><br>
We’ll explore Quarto's unique Lua support, including custom AST nodes and helper functions, showcasing how both straightforward and advanced techniques can transform your documents. Through practical examples, you'll gain the confidence to extend Quarto's functionality and unlock new possibilities. 
<br><br>
Join us to elevate your Quarto projects and contribute to its growing ecosystem!

**Speaker name:** Christophe Dervieux
**Job title:** Open Source Software Engineer
**Company:** 
**Bio:**
NA"
Breakout Session,Shiny New Tricks,"## Title: Old Apps, New Tricks: How AI can write Automated Tests for your Shiny Apps
**Code:** PAR-021
**Session type:** Breakout Session

**Abstract:**
As Shiny applications grow in complexity, comprehensive testing becomes crucial yet often overlooked. Many developers struggle to implement proper testing due to time constraints and technical barriers. To address this challenge, we're introducing an innovative solution that automatically generates regression tests for existing Shiny apps. By leveraging AI models trained on testing best practices, the Shiny package will streamline the testing process, making it more accessible and efficient for developers of all skill levels.

**Speaker name:** Karan Gathani
**Job title:** Software QA Engineer
**Company:** Posit PBC
**Bio:**
Karan is currently a Shiny Software QA Engineer at Posit. Karan has a history of working with tech startups in the San Francisco Bay Area helping them ship products efficiently without compromising on quality. In his spare time, he likes to participate in BioBlitzes organized around the Bay Area and contributing to this natural history blog.

## Title: Playing nice with ecosystems: cross-platform anywidgets for interactive computing
**Code:** PAR-021
**Session type:** Breakout Session

**Abstract:**
anywidget is a specification and toolkit for authoring reusable interactive widgets, bridging modern web technologies with Python. It defines a standard for interactive elements that work across Jupyter, VS Code, Positron IDE, and web frameworks like Shiny for Python and Solara. While many platforms integrate anywidget through a Jupyter-compatibility layer, others have adopted it natively, extending its reach beyond Jupyter. This decoupling has also enabled early experiments with non-Python runtimes like R and Deno. By prioritizing flexibility and interoperability, anywidget helps library developers make their tools more widely usable and enables framework authors to bootstrap rich interactive ecosystems without platform lock-in.

**Speaker name:** Trevor Manz
**Job title:** Engineer
**Company:** marimo
**Bio:**
NA

## Title: Teaching Shiny Assistant Kung-Fu
**Code:** PAR-021
**Session type:** Breakout Session

**Abstract:**
Teaching an Artificial Intelligence (AI) to utilize a newly developed Python package is nearly impossible without access to the system prompt. Large Language Models (LLMs) excel at code generation, but they lack the knowledge to interact seamlessly with new, untrained packages. In this presentation, I will demonstrate how Shiny Assistant automatically enhances its system prompt based on the required Python packages for the user’s Shiny Application. This generated prompt leverages the packages’ existing documentation and computed strong types. Providing this additional dynamic context delivers a custom Shiny Assistant experience, tailored to the user's needs.

**Speaker name:** Barret Schloerke
**Job title:** Shiny Team Software Engineer
**Company:** Posit
**Bio:**
`hello()`! Dr. Barret Schloerke is a Shiny Software Engineer at Posit. He created and maintains many R packages surrounding the Shiny ecosystem, including {shinylive}, {shinytest2}, and {reactlog}. In addition to his work in R, Barret also works on Shiny for Python, implementing its testing tools, bookmarking, and interactive data frame experience.

## Title: shinystate: Launching collaboration and session management to new heights in Shiny applications
**Code:** PAR-021
**Session type:** Breakout Session

**Abstract:**
Shiny is being used more regularly as a front end to sophisticated workflows in data science, often with a large number of inputs and intricate reactivity. End users desire a way to save their progress through the application workflow and share their state of the application with others for review. For small applications, the existing Shiny bookmarkable state feature is a valid approach. However, many of the production Shiny applications I've created require more granular control. Enter {shinystate}, my new R package that offers an intuitive class system and integration with {pins} to let developers choose where to save application state, ability to save multiple sessions at once, and bring collaboration to new heights for end users.

**Speaker name:** Eric Nantz
**Job title:** Statistician
**Company:** Eli Lilly
**Bio:**
Eric Nantz is a director within the statistical innovation center at Eli Lilly and Company, creating analytical pipelines and capabilities of advanced statistical methodologies for clinical design used in multiple phases of development. Outside of his day job, Eric is passionate about connecting with and showcasing the brilliant R community in multiple ways. You may recognize his voice from the [R-Podcast](https://r-podcast.org) that he launched in 2012. Eric is also the creator of the [Shiny Developer Series](https://shinydevseries.com) where he interviews authors of Shiny-related packages and practitioners developing applications, as well as sharing his own R and Shiny adventures via livestreams on his [Twitch channel](https://twitch.tv/rpodcast). In addition, Eric is a curator for the [RWeekly project](https://rweekly.org) and co-host of the [RWeekly Highlights podcast](https://rweekly.fireside.fm) which accompanies every issue."
Breakout Session,Shiny for Humans,"## Title: Modular, layout-as-code approach for customizable Shiny dashboards
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
To improve government supervision in the healthcare space, we have designed a Shiny dashboard that enables us to adhere to GDPR and other regulations and share different bits of information with different types of stakeholders. For that, we have implemented a ‘layout-as-code’ system where each user can have its own layout of pages and modules, stored as json in the database. Users have the option to drag and drop modules to different locations or change the layout altogether, adding and removing modules as needed! 
<br>For developers, this system of loosely coupled modules helps to quickly contribute to the project as a new module needs only a couple of lines of code to integrate it within the framework.

**Speaker name:** Kim Schouten
**Job title:** Data scientist
**Company:** Nederlandse Zorgautoriteit (Dutch Healthcare Authority)
**Bio:**
NA

## Title: shinyGovStyle - accessible government design in RShiny
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
In the UK, we are required to make public sector websites accessible to all users. While there is a wealth of UK government data is publicly available, it can be tough to engage with. Government analysts are increasingly turning to R Shiny aim to enhance their data dissemination, making it more engaging for users, but how can they do this consistently and in a way that carries the same trustworthiness and authority as a domain such as GOV.UK? Enter shinyGovstyle, a package crafted by UK government analysts that seamlessly incorporates GOV.UK's frontend design components into shiny functions, allowing R users to effortlessly add them to their apps, emulating the design of other GOV.UK services and saving hours of development time.

**Speaker name:** Cam Race
**Job title:** Lead Product Manager and Statistician
**Company:** Department for Education (UK)
**Bio:**
NA

## Title: shinyGovStyle - accessible government design in RShiny
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
In the UK, we are required to make public sector websites accessible to all users. While there is a wealth of UK government data is publicly available, it can be tough to engage with. Government analysts are increasingly turning to R Shiny aim to enhance their data dissemination, making it more engaging for users, but how can they do this consistently and in a way that carries the same trustworthiness and authority as a domain such as GOV.UK? Enter shinyGovstyle, a package crafted by UK government analysts that seamlessly incorporates GOV.UK's frontend design components into shiny functions, allowing R users to effortlessly add them to their apps, emulating the design of other GOV.UK services and saving hours of development time.

**Speaker name:** Sarah Wong-Brown
**Job title:** Head of Statistics Development and Flexible Analysis
**Company:** UK Civil Service (HMRC)
**Bio:**
NA

## Title: Death by Dropdown? How to Build Shiny Apps That Guide—Not Overwhelm—Your Users
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
Opening a Shiny app to endless dropdowns leads to disengagement and decision fatigue—“death by dropdown”. This talk introduces the Behavioral Insights Design (BID) Framework, a structured, psychology-driven approach to reducing cognitive overload and enhance usability. The five stages—Notice the Problem, Interpret Needs, Structure UI, Anticipate Behavior, and Validate & Empower Users—leverage concepts like Cognitive Load Theory, Processing Fluency, and Data Storytelling to guide users toward insights. Attendees seeking to build intuitive, engaging, and impactful applications will leave with a clear roadmap for reducing friction in data exploration, along with practical techniques they can apply using tools like {reactable} or {echarts4r}.

**Speaker name:** Jeremy Winget, PhD
**Job title:** Full Stack Developer
**Company:** SKIM
**Bio:**
Jeremy Winget, PhD, is a full-stack developer and computational social scientist with deep expertise in group dynamics and agent-based modeling. He designs intuitive, data-driven applications that integrate cutting-edge AI, ML, and NLP, bridging technical rigor with behavioral insight. Jeremy builds scalable tools that support impactful decision-making across domains, with a focus on socially responsible innovation and user-centered design.

## Title: Death by Dropdown? How to Build Shiny Apps That Guide—Not Overwhelm—Your Users
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
Opening a Shiny app to endless dropdowns leads to disengagement and decision fatigue—“death by dropdown”. This talk introduces the Behavioral Insights Design (BID) Framework, a structured, psychology-driven approach to reducing cognitive overload and enhance usability. The five stages—Notice the Problem, Interpret Needs, Structure UI, Anticipate Behavior, and Validate & Empower Users—leverage concepts like Cognitive Load Theory, Processing Fluency, and Data Storytelling to guide users toward insights. Attendees seeking to build intuitive, engaging, and impactful applications will leave with a clear roadmap for reducing friction in data exploration, along with practical techniques they can apply using tools like {reactable} or {echarts4r}.

**Speaker name:** Milena Eickhoff
**Job title:** Web & R Shiny Developer
**Company:** 
**Bio:**
NA

## Title: Design of Everyday Shiny Apps
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
Donald Norman’s Design of Everyday Things shows how even smart people struggle with bad design—flipping the wrong switch, pushing a door instead of pulling. The same issues exist in Shiny apps, where function often outweighs experience. But as a Shiny developer, you are the door designer, and it’s your responsibility to create user-friendly tools. Not to worry—good design isn’t just for designers. You don’t need an art degree to build intuitive, visually appealing apps. This talk covers composition, color theory, scale, and proportion—practical rules to improve usability. We’ll show real-world examples and code-based strategies to bring these principles to life. Because good design isn’t a luxury—it’s a necessity.

**Speaker name:** Casey Aguilar-Gervase
**Job title:** Senior Developer
**Company:** Atorus Research
**Bio:**
Casey Aguilar-Gervase is a Senior Developer at Atorus Research, where she builds and reimagines Shiny applications with a focus on clean design and effortless user experience. She’s passionate about making complex data feel approachable through thoughtful UI/UX. Based in Denver, Casey also competes internationally for Puerto Rico in Olympic Weightlifting and spends her free time with her two rescue dogs.

## Title: Design of Everyday Shiny Apps
**Code:** PAR-020
**Session type:** Breakout Session

**Abstract:**
Donald Norman’s Design of Everyday Things shows how even smart people struggle with bad design—flipping the wrong switch, pushing a door instead of pulling. The same issues exist in Shiny apps, where function often outweighs experience. But as a Shiny developer, you are the door designer, and it’s your responsibility to create user-friendly tools. Not to worry—good design isn’t just for designers. You don’t need an art degree to build intuitive, visually appealing apps. This talk covers composition, color theory, scale, and proportion—practical rules to improve usability. We’ll show real-world examples and code-based strategies to bring these principles to life. Because good design isn’t a luxury—it’s a necessity.

**Speaker name:** Maya Gans
**Job title:** Associate Director
**Company:** Atorus Research
**Bio:**
I am currently an Associate Director at Atorus Research where I develop custom applications using R and JavaScript. As an RStudio intern I designed TidyBlocks, a visual block based programming language. I also co-wrote JavaScript for Data Science. I use ggplot2 and d3.js to create music related infographics for JamBase.com. When I’m not coding, I’m climbing tall mountains."
Breakout Session,Sparking Development Joy,"## Title: Enemies to lovers: How non-programmers can make sparks fly when using testthat during package development
**Code:** PAR-022
**Session type:** Breakout Session

**Abstract:**
You’re just a data scientist, self-taught in R, trying to find your way in the world of package development. It’s just a package named testthat, hoping to help a developer make sure their package is operating as intended. You meet. You hate each other. The package seems a little daunting and quite frankly, a little tedious. Surely only “real” programmers use this! The package thinks you’re inept for not immediately putting it to use. As fate would have it, you attend this talk and discover you are indeed compatible. Sparks fly, a package is born. This talk will help less experienced programmers learn about testing, automated workflows, how to write good tests, and why it’s all worth it when it pays off in quality and efficiency. Steamy.

**Speaker name:** Libby McKenna
**Job title:** Water Process Engineer
**Company:** Brown and Caldwell
**Bio:**
Libby is an environmental engineer at Brown and Caldwell in Denver, CO. She uses R daily for data cleaning, modeling, data visualization, and package development. She and her development team recently created tidywater, a CRAN-accessible package that consolidates drinking water quality models. Libby was also the lead developer for the Shiny app that showcases the tidywater models: bit.ly/BCOpenWTP 

## Title: Air - A blazingly fast R code formatter
**Code:** PAR-022
**Session type:** Breakout Session

**Abstract:**
In Python, Rust, Go, and many other languages, code formatters are widely loved. They run on every save, on every pull request, and in git pre-commit hooks to ensure code consistently looks its best at all times.
<br><br>
In this talk, you'll learn about Air, a new R code formatter. Air is extremely fast, capable of formatting individual files so fast that you'll question if its even running, and of formatting entire projects in under a second. Air integrates directly with your favorite IDEs, like Positron, RStudio, and VS Code, and is available on the command line, making it easy to standardize on one tool even for teams using various IDEs.
<br><br>
Once you start using Air, you'll never worry about code style ever again!

**Speaker name:** Davis Vaughan
**Job title:** Senior Software Engineer
**Company:** Posit
**Bio:**
Davis is a software engineer at Posit working on improving various aspects of the tidyverse - from high level packages like dplyr and tidyr, to lower level ones like vctrs. Outside of the tidyverse, he manages a number of other R packages including slider, furrr, and clock.

## Title: Air - A blazingly fast R code formatter
**Code:** PAR-022
**Session type:** Breakout Session

**Abstract:**
In Python, Rust, Go, and many other languages, code formatters are widely loved. They run on every save, on every pull request, and in git pre-commit hooks to ensure code consistently looks its best at all times.
<br><br>
In this talk, you'll learn about Air, a new R code formatter. Air is extremely fast, capable of formatting individual files so fast that you'll question if its even running, and of formatting entire projects in under a second. Air integrates directly with your favorite IDEs, like Positron, RStudio, and VS Code, and is available on the command line, making it easy to standardize on one tool even for teams using various IDEs.
<br><br>
Once you start using Air, you'll never worry about code style ever again!

**Speaker name:** Lionel Henry
**Job title:** Software Engineer
**Company:** Posit
**Bio:**
I'm a software developer at Posit, initially focused on low-level packages for the tidyverse, and now working on modern development tools for R.

## Title: Making Things Nice in Python
**Code:** PAR-022
**Session type:** Breakout Session

**Abstract:**
When working on the Great Tables and Pointblank Python packages, we've tried to make them 'nice'. These packages give you a lot of convenient options, and a large volume of docs and examples. In the Python world, this might be received differently than it would be in R. Whether it was integrating Polars selectors in Great Tables or accepting a multitude of DataFrames and DB tables in Pointblank, these design choices can be seen as surprising things to established Python developers.
<br><br>
However, I argue it's good to be doing this! People are benefitting from these approaches. I'll share a few of these developer stories with the takeaway being that Python packages could and should pay attention to good user experience.

**Speaker name:** Rich Ianonne
**Job title:** Software Engineer
**Company:** 
**Bio:**
Rich is a software engineer that enjoys working with R and Python. He likes to create packages that help people to accomplish things. While Rich very clearly digs software development activities, he enjoys other things as well! Examples include: playing and listening to music, reading books, watching films, meeting up with friends, and wandering through the many valleys and ravines of the Greater Toronto Area.

## Title: The Curse of Documentation
**Code:** PAR-022
**Session type:** Breakout Session

**Abstract:**
In Greek mythology, Tantalus was doomed to stand with a lake of water below him and branches of fruit close above. When he went to drink the water it receded, and when he reached to eat the fruit it was blown beyond his grasp. What he needed was forever at arms length.
<br><br>
Software documentation often puts users in a similar bind. The information is there, but something doesn’t quite connect. Maybe you try and fail to adapt an example to your use case. Maybe it’s unclear how a bunch of functions fit together.
<br><br>
In this talk, I'll discuss how effective user guides--like R for Data Science and the React.js guide--break the curse. I'll focus on three factors behind effective guides: strategic information, inductive learning, and task sequencing.

**Speaker name:** Michael Chow
**Job title:** 
**Company:** 
**Bio:**
Michael Chow. Human memory, statistics, and computing."
Breakout Session,Strengthening the R Ecosystem,"## Title: Purrrfectly parallel, purrrfectly distributed
**Code:** PAR-010
**Session type:** Breakout Session

**Abstract:**
purrr is a powerful functional programming toolkit that has long been a cornerstone of the tidyverse. In 2025, it receives a modernization that means you can use it to harness the power of all computing cores on your machine, dramatically speeding up map operations.
<br><br>
More excitingly, it opens up the doors to distributed computing. Through the mirai framework used by purrr, this is made embarrassingly simple. For those in small businesses, or even large ones – every case where there is a spare server in your network, you can now put to good use in simple, straightforward steps.
<br><br>
Let us show you how distributed computing is no longer the preserve of those with access to high performance compute clusters.

**Speaker name:** Charlie Gao
**Job title:** Senior Software Engineer
**Company:** Posit
**Bio:**
Charlie Gao is a senior software engineer on the Open Source team at Posit, where he focuses on advancing asynchronous, high-concurrency, and high-performance tooling in the R ecosystem. He is the creator of the mirai async framework and works with the tidyverse and Shiny teams to introduce new capabilities, such as event-driven async in the httr2 and ellmer packages.

## Title: R-multiverse: a next-generation R package repository system built on R-universe
**Code:** PAR-010
**Session type:** Breakout Session

**Abstract:**
R-multiverse is a new R package repository system and a home for packages outside the scope of CRAN/Bioconductor. Each package is registered once, and then maintainers directly control releases through GitHub/GitLab. R-multiverse hosts a Community repository with the latest release of each package, and a Production repository with quarterly snapshots of the releases from Community that pass automated checks. Built on R-universe and GitHub, R-multiverse is mostly automated. R-multiverse originated from the R Consortium Repositories Working Group, it has transparent governance, and it operates in a collaborative and open way. It is not mature or established yet, but it is under active development, and it is ready for package contributions.

**Speaker name:** Will Landau
**Job title:** Senior Advisor – Innovative Statistics
**Company:** Eli Lilly and Company
**Bio:**
Will Landau is a statistician and software developer in the life sciences. He develops methods and tools for Bayesian statistics, clinical trials, and reproducible analysis pipelines. Will created the {targets} package and co-leads R-multiverse.

## Title: How to make {renv} actually work
**Code:** PAR-010
**Session type:** Breakout Session

**Abstract:**
The {renv} package aims to *help* users create reproducible environments for R projects. In theory, this is great! In practice, restoring a package environment can be a frustrating process due to overlooked R configuration requirements. Join me to better understand the source of environment restoration issues and learn strategies for successful  maintenance of {renv}-backed projects.

**Speaker name:** Shannon Pileggi
**Job title:** Associate Director of Data Science
**Company:** The Prostate Cancer Clinical Trials Consortium
**Bio:**
Shannon Pileggi (she/her) is an Associate Director of Data Science at The Prostate Cancer Clinical Trials Consortium, an occasional blogger, and a member of the R-Ladies Global leadership team. She enjoys automating data wrangling and data outputs, and making both data insights and learning new material digestible.

## Title: Extending the horizons of R with Rust
**Code:** PAR-010
**Session type:** Breakout Session

**Abstract:**
Data volumes have skyrocketed for years, outpacing advances in hardware. When R users hit performance bottlenecks, the traditional remedy has been to reach for C++ and include it in their R code using Rccp. In the last few years Rust has emerged as a modern, high-performance alternative for extending R. In this talk, we’ll explore why Rust is a natural fit for data teams—from its robust safety to its concurrency advantages. You’ll also see real-world case studies of how organizations are leveraging Rust and R together to tackle large-scale, compute-intensive challenges. Join us to learn how Rust is expanding the horizons of what’s possible in R, some tips on extending R with Rust, and how your team can benefit from these new possibilities.

**Speaker name:** Andrés Quintero
**Job title:** Data Professional
**Company:** ixpantia
**Bio:**
Andrés Quintero is a Data Engineer and Country Director for ixpantia in Colombia. He leverages Python, R, and Rust to solve complex data challenges in global organizations and actively contributes to open-source by developing high-performance tools and libraries that significantly enhance productivity and efficiency for data teams worldwide."
Breakout Session,Teaming Up with Posit Products,"## Title: Bilingual Machine Learning with Vetiver and Connect
**Code:** PAR-003
**Session type:** Breakout Session

**Abstract:**
This talk encourages using the right tool for the right job and focuses on how to approach paired programming, how to collaborate bilingually (R and Python), and how to use vetiver and Connect to simplify the delivery of your data science products to non-technical users.

**Speaker name:** Kris Fabick
**Job title:** Data Scientist
**Company:** Nissan North America
**Bio:**
Kris is a former high school math teacher turned data scientist with a passion for efficiency, accuracy, and innovation. Equipped with experience in applied statistics, machine learning, mathematical optimization, programming in R and Python, SQL, and data visualization, Kris works at Nissan where he uses his creativity and problem-solving skills to build end-to-end data science solutions and enjoys teaching and guiding others on their own journeys into applied mathematics and data science.

## Title: Bilingual Machine Learning with Vetiver and Connect
**Code:** PAR-003
**Session type:** Breakout Session

**Abstract:**
This talk encourages using the right tool for the right job and focuses on how to approach paired programming, how to collaborate bilingually (R and Python), and how to use vetiver and Connect to simplify the delivery of your data science products to non-technical users.

**Speaker name:** Kristin Carr
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: Advancing Epigenetic Predictors with Scalable Machine Learning: A Biologist’s Perspective on Efficient Model Development
**Code:** PAR-003
**Session type:** Breakout Session

**Abstract:**
TruDiagnostic develops precision health tools using DNA methylation-based diagnostics. We integrate bioinformatics (R) and machine learning (Python) with Posit’s ecosystem in AWS to enable high-throughput model development. Posit enhances workflows by streamlining preprocessing, feature selection, and deep learning with PyTorch. Leveraging Posit with AWS parallelization and sharding accelerates model training, reducing computation from weeks to hours. This talk highlights how Posit is vital for advancing research in health predictors, driving innovation in precision medicine and revolutionizing healthcare.

**Speaker name:** Varun Dwaraka
**Job title:** Director of Bioinformatics and Principal Investigator
**Company:** TruDiagnostic
**Bio:**
Dr Varun B. Dwaraka is a computational and bioinformatics scientist with significant expertise in ageing, epigenetics, and biomarker identification. As the Head of Bioinformatics at TruDiagnostic, he leads a dedicated team developing advanced machine-learning models to uncover epigenetic biomarkers, focusing on understanding molecular ageing and its associations with disease and mortality risk. Dr. Dwaraka’s work integrates multi-omic data, incorporating metabolic, proteomic, phenotypic, and DNA methylation measures, enabling him to establish novel age-predictive algorithms critical to advancing age-related research. Dr Dwaraka’s background includes a Ph.D. in Biology from the University of Kentucky, where he specialized in the genetic and epigenetic foundations of tissue regeneration in salamanders. His undergraduate training in Molecular, Cellular, and Developmental Biology from the University of California, Santa Cruz, focused on bioinformatics. Throughout his career, he has contributed to high-impact bioinformatics and multi-omic research initiatives at institutions such as Harvard, Yale, Cornell, UCSC, UCSF and the Carnegie Institute of Science, and his insights have been published in leading peer-reviewed journals like Nature Aging and Genome Medicine. 

In addition to his research, Dr Dwaraka is a Principal Investigator at TruDiagnostic, spearheading scientific projects that have attracted attention from prominent media outlets like Forbes, BBC, and Men’s Health. His contributions to popular documentaries on platforms like Netflix and HBO highlight the real-world implications of his research in public health and ageing. A full member of the Sigma Xi Scientific Research Honor Society and a 2023 Foresight Fellow in Biotechnology and Health Expansion, Dr. Dwaraka is an active scientific contributor in the field of aging and epigenetics, presenting as an invited speaker at international conferences and prestigious academic gatherings. 

Dr. Dwaraka serves on numerous scientific advisory boards, notably SRW Laboratories; serves as faculty at the Geneva College of Longevity Sciences in Geneva, Switzerland; and serves as the Director of Epigenomics on the American Board of Precision Medicine. 

## Title: Automating for Consistency
**Code:** PAR-003
**Session type:** Breakout Session

**Abstract:**
In pharma, our data can be limited, inconsistent or incomplete, and data cleaning can be time-consuming. In addition, the industry is highly regulated, and data transformations must be transparent. At Pfizer, we developed a custom R package that enables us to automatically quality control our clinical biomarker data. Our package allows for flexible data structures and external input by non-coders, producing consistent reports and clear documentation. In this session I will share some features of our package, as well as how automating our process has been a powerful tool enabling us to achieve consistency, with the hope that this helps others automate their own pipelines.

**Speaker name:** Kristin Mussar
**Job title:** Manager, Translational Oncology Bioinformatics
**Company:** Pfizer
**Bio:**
NA

## Title: Data Science Hangout at posit::conf(2025)
**Code:** PAR-003
**Session type:** Breakout Session

**Abstract:**
The Data Science Hangout has been a weekly online gathering for the data science community since July 2021. Each week, a different leader helps us kick off our open discussion about leadership, career lessons, workflows, and other relevant topics. These ""no slide"" sessions have been well-received by attendees over the years. Let’s get together for a Data Science Hangout-style session at posit::conf(2025). We’ll have 3-4 data science leaders join us live on stage to share their experience and open up the conversation with the whole room. No presentations required :)

**Speaker name:** Rachael Dempsey
**Job title:** 
**Company:** 
**Bio:**
NA"
Breakout Session,The Power of Presentation,"## Title: Disposable Shiny Apps
**Code:** PAR-008
**Session type:** Breakout Session

**Abstract:**
Many data scientists find themselves building Shiny apps for one-off presentations, client meetings, or teaching demonstrations. These ""disposable"" apps can suffer from overengineering, leading to unnecessary development time and complexity. Or, the apps never get built because the development hill is too high to climb. This talk covers disposable Shiny apps - intentionally minimal applications designed for specific, short-term needs. We'll explore strategies for rapid development, including reusable templates, coding assistants, efficient styling, and design principles that prioritize speed and clarity. This talk will show how this approach can transform a typical week-long development process into a few hours while maintaining polish.

**Speaker name:** James Wade
**Job title:** Research Scientist
**Company:** Dow
**Bio:**
James Wade is a Research Scientist working in the chemicals and materials science industry where he combines the power of data science with chemistry and materials science. His current projects focus on augmenting materials characterization innovations with statistical analysis, machine learning, and data visualization. James enjoys contributing to a growing data science community both in and outside of work and is a passionate advocate of open-source data science.

## Title: Quarto for Business Collaboration and Technical Documentation in Word docx format
**Code:** PAR-008
**Session type:** Breakout Session

**Abstract:**
Microsoft Word documents have remained a critical channel of statistical evidence and influence for the manufacturing of a safe and effective supply of therapies to treat diseases.  The incorporation of statistical content – narratives, graphs, and tables – into health authority dossiers worldwide requires speed in terms of days and sometimes hours to generate statistical source content for decision-making and official documentation. 
<br><br>
Quarto provides an efficient solution to address these needs.  This presentation illustrates and covers concepts of the solution that builds upon R and the Posit platform to reliably produce an automated and flexible workflow for figure and table captions, autonumbering, and cross-referencing in docx format.

**Speaker name:** Bill Pikounis
**Job title:** Senior Distinguished Scientist, Manufacturing Statistics
**Company:** Johnson & Johnson
**Bio:**
Bill Pikounis is a Senior Distinguished Scientist, Manufacturing Statistics, within Johnson & Johnson’s R&D pharmaceutical sector. He is the manufacturing statistical lead for CARVYKTI, a cell therapy. He received his Ph.D. from the University of Florida. Bill is an American Statistical Association (ASA) Fellow. His professional technical interests lie in data graphs, Bayesian methods, multilevel models, statistical computing, and software solutions. For details see http://billpikounis.net/ .

## Title: Talk data to me: How to present youR data to any audience
**Code:** PAR-008
**Session type:** Breakout Session

**Abstract:**
Translating data and analytics to diverse audiences is a vital part of any data scientists’ job, no matter what level. Strong data communication skills are valuable for every shiny app or quarto-generated presentation you give, and involve more than just avoiding pie charts! This presentation will cover creating a narrative with your data, identifying key messages, creating effective slides and visuals, and delivering an oral presentation that is not only articulate, but will help your audience understand and remember your message.

**Speaker name:** Freda Warner
**Job title:** Analyst
**Company:** Canadian Institutes of Health Research (CIHR)
**Bio:**
Freda is a data scientist with 10+ years of experience in epidemiological health research, data visualizations, and statistical modeling. Currently a Data Analyst at CIHR, she is passionate about making data accessible and engaging for any audience.

## Title: Theming Made Easy: Introducing brand.yml
**Code:** PAR-008
**Session type:** Breakout Session

**Abstract:**
brand.yml is an exciting new project from Posit that radically simplifies theming. Every data science tool supports some form of theme and appearance customization, but each app framework, output format, or visualization tool requires its own special syntax for theming.
<br><br>
The goal of brand.yml is to create a portable and unified interface for brand-related theming that can be used anywhere that data science artifacts are produced. As a collaboration between the Shiny and Quarto teams, brand.yml provides a single interface to setting baseline themes in reports and apps across the R and Python ecosystems.
<br><br>
In this talk, I’ll introduce brand.yml and showcase the many ways that brand.yml can bring consistent styles to your data science outputs.

**Speaker name:** Garrick Aden-Buie
**Job title:** Software Engineer, Shiny
**Company:** Posit
**Bio:**
<p>Garrick Aden-Buie is a software engineer for Shiny at Posit. He is passionate about building broadly accessible tools for data scientists in R and Python. Before joining the Shiny team, he helped build Posit Academy, an online, immersive, data science apprenticeship for professional teams. Garrick has been using and teaching Shiny since 2014, and he shares his experience and projects on his website at <a href=""https://www.garrickadenbuie.com/"" target=""_blank"">garrickadenbuie.com</a>.</p>"
Keynote,Keynote Session,"## Title: Keynote Session
**Code:** KEY-0001
**Session type:** Keynote

**Abstract:**
Stay tuned, more details to come soon!

**Speaker name:** Jonathan McPherson
**Job title:** Software Architect
**Company:** Posit Software, PBC
**Bio:**
Jonathan is a software architect and team leader at Posit, working primarily on the RStudio IDE, Posit Workbench, and related products and systems. He lives in the Pacific Northwest and drinks a lot of coffee. 

## Title: Keynote Session
**Code:** KEY-0002
**Session type:** Keynote

**Abstract:**
Stay tuned, more details to come soon!

**Speaker name:** Kieran Healy
**Job title:** Professor
**Company:** Duke University
**Bio:**
Kieran Healy teaches at Duke University, where he is Professor of Sociology. He studies the moral order exchange in market societies, the effect of measurement on social classification, and the links between these two topics. His most recent book, The Ordinal Society (https://theordinalsociety.com/, co-authored with Marion Fourcade), is about how the widespread availability of social data is transforming how the world is organized. He is also the author of Data Visualization: A Practical Introduction (https://socviz.co/); Last Best Gifts, a book about exchange in human blood and organs; and numerous articles across the social sciences and philosophy. He has been using R since it was a different letter. His website, https://kieranhealy.org/, has more than twenty years of public writing on these and other topics. 

## Title: Keynote Session
**Code:** KEY-0003
**Session type:** Keynote

**Abstract:**
Stay tuned, more details to come soon!

**Speaker name:** Cat Hicks
**Job title:** Psychologist for Software Teams
**Company:** Catharsis Consulting
**Bio:**
Cat Hicks is a psychologist for software teams and defender of the mismeasured. She is the author of the Developer Thriving framework, the AI Skill Threat framework, and the VP of Research at Pluralsight. Cat is the founder of the Developer Success Lab, an open science research lab that creates industry-changing empirical evidence about how organizations and individuals can achieve sustainable, resilient innovation in technology and create more wellbeing for technologists. Cat is also the founder of Catharsis Consulting, a scientific consultancy that connects organizations to human-centered evidence strategies. Cat holds a Ph.D. in Quantitative Experimental Psychology from UC San Diego, serves on the Advisory Council of the University of San Diego Center for Digital Civil Society, and is the author of a forthcoming book on the psychology of software teams. https://drcathicks.com/"
Lightning,Lightning Talks,"## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Sharon Machlis
**Job title:** Retired/Occasional Freelance Writer
**Company:** Former Computerworld & InfoWorld
**Bio:**
Sharon is a long-time tech journalist and R enthusiast with several years experience as a data science professional. Recently retired, she still writes occasional freelance articles for InfoWorld and Computerworld -- and now enjoys learning about generative AI. She is the author of Practical R for Mass Communication & Journalism (CRC Press) and the former host of InfoWorld's Do More With R video series. You can find her on Bluesky, Mastodon, and LinkedIn. Her hobby apps are at apps.machlis.com.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Cari Gostic
**Job title:** Air Quality Data Scientist
**Company:** Sonoma Technology
**Bio:**
Cari earned her M.S. in data science from the University of British Columbia in 2020. She currently works as a data scientist at Sonoma Technology, where she addresses wide-ranging questions related to air quality. She enjoys the transformation of raw pollutant monitoring data into useful insights through effective data visualization.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Dhruvi Sompura
**Job title:** Software Engineer
**Company:** Posit
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Mauro Lepore
**Job title:** Senior Software Engineer
**Company:** Recast
**Bio:**
I am a senior software engineer at Recast. I specialize in building and maintaining universes of R packages. I love learning and sharing knowledge. I’m also an associate editor at rOpenSci.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Alex Rossell Hayes
**Job title:** Senior Data Scientist
**Company:** YouGov America
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** David Schoch
**Job title:** Data Scientist & DevOps Engineer
**Company:** Cynkra
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Gordon Woodhull
**Job title:** Software Engineer, Quarto
**Company:** Posit, PBC
**Bio:**
Gordon Woodhull is a software engineer on the Quarto team, currently working on Typst, Dark Mode, and Jupyter Notebook functionality. He has interests in Visualization, Programming Languages, Document Systems, User Interfaces, games and cats. He lives in Beacon, NY.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Rebecca Hodge
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Ella Kaye
**Job title:** Research Software Engineer
**Company:** University of Warwick
**Bio:**
Ella is a Research Software Engineer at the University of Warwick, UK, and a fellow of the Software Sustainability Institute. She works to increase sustainability and EDI (Equality, Diversity and Inclusion) in the R Project. She also runs rainbowR, a community that connects, supports and promotes LGBTQ+ people who code in R, and spreads awareness of LGBTQ+ issues through data-driven activism. She enjoys R package development, powerlifting, bouldering, playing clarinet and time with her family.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Andrie de Vries
**Job title:** Director of Product Strategy
**Company:** 
**Bio:**
Andrie is Director of Product Strategy at Posit. He started using R in 2009 for market research statistics and joined Revolution Analytics in 2013, assisting customers with their adoption of R for machine learning. After the acquisition of Revolution analytics by Microsoft in 2015, he implemented deep learning and machine learning projects in the Azure cloud.

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Eric Scott
**Job title:** 
**Company:** 
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Rishabh Sharma Vemuri
**Job title:** SPA Student Assistant
**Company:** UNC Chapel Hill
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Abiye Berhanu
**Job title:** SPA Student Assistant
**Company:** UNC Chapel Hill
**Bio:**
NA

## Title: Lightning Talks
**Code:** TALK-1231
**Session type:** Lightning

**Abstract:**
There are 12 five-minute talks in this session. <br><br>
<li> Use Your Data Skills for Good: Ideas for Community Service </li>
<li> Mapping sub-daily fire detections of historical California wildfires on demand with Sfarrow </li>
<li> Multiple Console Sessions in Positron </li>
<li> Approaching Positron from VS Code or RStudio </li>
<li> It's all fun and games til your analysis code is finished: the player package in R </li>
<li> Brand YML in Quarto </li>
<li> Automating Event Scheduling with Python in Positron </li>
<li> Birthing the pregnancy package </li>
<li> Putting an {ellmer} AI in production with the blessing of IT </li>
<li> Enabling geospatial workflow management with targets: an R package origin story </li>
<li> Plotgardener – Genomic Data Visualization Made Easy </li>
<li> What we're doing to make Quarto fast(er) </li>

**Speaker name:** Carlos Scheidegger
**Job title:** Software Engineer
**Company:** 
**Bio:**
Carlos is a software engineer working on Quarto (https://quarto.org). Before joining Posit, he was a professor of Computer Science and, in one way or another, he's been working on tools for computational reproducibility for just under two decades."
Talk,Get the Latest on Posit's Commercial Products,"## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Kelly O'Briant
**Job title:** Product Manager
**Company:** 
**Bio:**
Kelly O'Briant is the product manager for Posit Connect.

## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Tom Mock
**Job title:** 
**Company:** Posit
**Bio:**
NA

## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Joe Roberts
**Job title:** Product Manager
**Company:** Posit
**Bio:**
Joe is the Product Manager for Posit Package Manager, with a focus on helping customers navigate the challenges of enterprise package management for data science. He has a background in software engineering and has spent his entire career developing data analysis software, while always looking for the next big problems to solve.

## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Kara Woo
**Job title:** Senior Software Engineer
**Company:** Posit
**Bio:**
NA

## Title: Keeping Data Alive: Persistent Storage Options for Dynamic Cloud Applications
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Alex Chisholm
**Job title:** Product Manager, Cloud Platforms
**Company:** Posit
**Bio:**
Alex Chisholm is a data professional turned product manager. He works at Posit on Posit Cloud, shinyapps.io, and Connect Cloud, a new online publishing platform for data applications and documents. Prior to joining Posit, Alex lived in Amsterdam, NL where he worked for an online travel startup and an education insights company. He now lives in Pittsburgh, PA with his wife and two daughters.

## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Chetan Thapar
**Job title:** 
**Company:** Posit
**Bio:**
NA

## Title: Get the Latest on Posit's Commercial Products
**Code:** TALK-1211
**Session type:** Talk

**Abstract:**
Join us for an overview of the latest developments across Posit’s commercial product ecosystem. This session will cover Posit Workbench, Package Manager, Connect, Connect Cloud, and our growing portfolio of managed services including Snowflake and beyond. Hear directly from the product managers and engineers who are building these tools, and get insights into what’s coming next.

**Speaker name:** Steve Nolen
**Job title:** Engineering Manager
**Company:** Posit
**Bio:**
NA"
Workshop,"Branded Websites, Presentations, Dashboards, and PDFs with Quarto","## Title: Branded Websites, Presentations, Dashboards, and PDFs with Quarto
**Code:** WS-008
**Session type:** Workshop

**Abstract:**
Join us for a hands-on, one-day workshop at posit::conf(2025), where we’ll explore the versatility of Quarto output formats. Designed for data scientists, analysts, and content creators, this immersive session will teach you how to craft cohesive reports and presentations while refining your workflow with Quarto’s latest features.
<br><br>
You will learn how to create dynamic websites, professional PDF documents, engaging presentations, and interactive dashboards using Quarto. This workshop highlights Quarto's powerful theming capabilities, including the new support for brand.yml, which ensures that your work maintains a professional and cohesive style across all formats.
<br><br>
By the end of the session, you’ll be equipped to:
<ul>
<li> Build and deploy Quarto websites.</li>
<li> Generate professional presentations and PDF reports.</li>
<li> Create interactive dashboards for data visualization and reporting.</li>
<li> Use brand.yml to define and apply consistent theming across all outputs.</li>
</ul>
Whether you're looking to enhance your personal projects or streamline organizational outputs, this workshop will equip you with the tools to create polished, professional results.
<br><br>

**Speaker name:** Isabella Velásquez
**Job title:** Sr. Product Marketing Manager
**Company:** Posit
**Bio:**
NA

## Title: Branded Websites, Presentations, Dashboards, and PDFs with Quarto
**Code:** WS-008
**Session type:** Workshop

**Abstract:**
Join us for a hands-on, one-day workshop at posit::conf(2025), where we’ll explore the versatility of Quarto output formats. Designed for data scientists, analysts, and content creators, this immersive session will teach you how to craft cohesive reports and presentations while refining your workflow with Quarto’s latest features.
<br><br>
You will learn how to create dynamic websites, professional PDF documents, engaging presentations, and interactive dashboards using Quarto. This workshop highlights Quarto's powerful theming capabilities, including the new support for brand.yml, which ensures that your work maintains a professional and cohesive style across all formats.
<br><br>
By the end of the session, you’ll be equipped to:
<ul>
<li> Build and deploy Quarto websites.</li>
<li> Generate professional presentations and PDF reports.</li>
<li> Create interactive dashboards for data visualization and reporting.</li>
<li> Use brand.yml to define and apply consistent theming across all outputs.</li>
</ul>
Whether you're looking to enhance your personal projects or streamline organizational outputs, this workshop will equip you with the tools to create polished, professional results.
<br><br>

**Speaker name:** Sara Altman
**Job title:** 
**Company:** Posit
**Bio:**
NA"
Workshop,Causal Inference in R,"## Title: Causal Inference in R
**Code:** WS-013
**Session type:** Workshop

**Abstract:**
In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting.
<br> <br>
In both data science and academic research, prediction modeling is often not enough; to answer many questions, we need to approach them causally. In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting. We’ll also show that by distinguishing predictive models from causal models, we can better take advantage of both tools. You’ll be able to use the tools you already know–the tidyverse, regression models, and more–to answer the questions that are important to your work.
<br><br>
This workshop is for you if you:
<ul>
<li> know how to fit a linear regression model in R, </li>
<li> have a basic understanding of data manipulation and visualization using tidyverse tools, and </li>
<li> are interested in understanding the fundamentals behind how to move from estimating correlations to causal relationships. </li>
</ul>

**Speaker name:** Malcolm Barrett
**Job title:** Research Software Engineer
**Company:** Stanford University
**Bio:**
<p><u><a href=""https://malco.io/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Malcolm Barrett</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;""> is an epidemiologist and research software engineer at Stanford University. After receiving his Ph.D. in epidemiology from the University of Southern California, he worked as a data scientist at Apple and Posit. His work has focused on causal inference methodology and software development, including many R packages for causal inference.</span></p>

## Title: Causal Inference in R
**Code:** WS-013
**Session type:** Workshop

**Abstract:**
In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting.
<br> <br>
In both data science and academic research, prediction modeling is often not enough; to answer many questions, we need to approach them causally. In this workshop, we’ll teach the essential elements of answering causal questions in R through causal diagrams, and causal modeling techniques such as propensity scores and inverse probability weighting. We’ll also show that by distinguishing predictive models from causal models, we can better take advantage of both tools. You’ll be able to use the tools you already know–the tidyverse, regression models, and more–to answer the questions that are important to your work.
<br><br>
This workshop is for you if you:
<ul>
<li> know how to fit a linear regression model in R, </li>
<li> have a basic understanding of data manipulation and visualization using tidyverse tools, and </li>
<li> are interested in understanding the fundamentals behind how to move from estimating correlations to causal relationships. </li>
</ul>

**Speaker name:** Lucy D'Agostino McGowan
**Job title:** Assistant Professor
**Company:** Wake Forest University
**Bio:**
Lucy D’Agostino McGowan is an assistant professor in the Department of Statistical Sciences at Wake Forest University. She received her PhD in Biostatistics from Vanderbilt University and completed her postdoctoral training at Johns Hopkins University Bloomberg School of Public Health. Her research focuses on analytic design theory, statistical communication, causal inference, and data science pedagogy. Dr. D’Agostino McGowan can be found blogging at livefreeordichotomize.com, on Twitter @LucyStats, and podcasting on the American Journal of Epidemiology partner podcast, Casual Inference."
Workshop,Data Science Workflows with Posit Tools - Python Focus,"## Title: Data Science Workflows with Posit Tools - Python Focus
**Code:** WS-020
**Session type:** Workshop

**Abstract:**
This Python-focused workshop will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modelling, and more. We’ll use Posit’s open-source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.
<br><br>
This course is for you if you:
<br>
<li> Build finished data products starting from raw data and are looking to improve your workflow </li>
<li> Are looking to expand your knowledge of Posit open source and professional tools </li>
<li> Want to improve interoperability between data products in your work or on your team </li>
<li> Have experience developing in Python. An analogous course with an R focus is also offered </li>
<br>

**Speaker name:** Sam Edwardes
**Job title:** Senior Solutions Engineer
**Company:** Posit
**Bio:**
Sam Edwardes is a Senior Solutions Engineer at Posit. He is passionate about helping customers maximize the value of Posit's professional and open-source products. He particularly enjoys working with customers who use Python or Kubernetes.

## Title: Data Science Workflows with Posit Tools - Python Focus
**Code:** WS-020
**Session type:** Workshop

**Abstract:**
This Python-focused workshop will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modelling, and more. We’ll use Posit’s open-source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.
<br><br>
This course is for you if you:
<br>
<li> Build finished data products starting from raw data and are looking to improve your workflow </li>
<li> Are looking to expand your knowledge of Posit open source and professional tools </li>
<li> Want to improve interoperability between data products in your work or on your team </li>
<li> Have experience developing in Python. An analogous course with an R focus is also offered </li>
<br>

**Speaker name:** Michael Beigelmacher
**Job title:** Solutions Engineer
**Company:** Posit
**Bio:**
NA"
Workshop,Data Science Workflows with Posit Tools - R Focus,"## Title: Data Science Workflows with Posit Tools - R Focus
**Code:** WS-019
**Session type:** Workshop

**Abstract:**
In this R-focused workshop, we will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modeling, and more. We’ll use Posit’s open source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.
<br><br>
This course is for you if you:
<br>
<li> Build finished data products starting from raw data and are looking to improve your workflow </li>
<li> Are looking to expand your knowledge of Posit open source and professional tools </li>
<li> Want to improve interoperability between data products in your work or on your team </li>
<li> Have experience developing in R. An analogous course with a Python focus is also offered. </li>
<br><br>

**Speaker name:** Katie Masiello
**Job title:** Solutions Engineer
**Company:** Posit
**Bio:**
Katie Masiello is a Solutions Engineer at Posit. A mechanical engineer by training, she found her calling in data science while working statistical analysis in the aerospace industry. A good cup of coffee, reproducibility, and making life easier for the next user are three things she loves most. Katie is an avid knitter and knitr, and she can often be found trying to tame her ridiculously overgrown garden, collecting pebbles, or thinking about taking up running as a hobby.

## Title: Data Science Workflows with Posit Tools - R Focus
**Code:** WS-019
**Session type:** Workshop

**Abstract:**
In this R-focused workshop, we will discuss ways to improve your data science workflows! During the course, we will review packages for data validation, alerting, modeling, and more. We’ll use Posit’s open source and professional tools to string all the pieces together for an efficient workflow. We’ll discuss environments, managing deployed content, working with databases, and interoperability across data products.
<br><br>
This course is for you if you:
<br>
<li> Build finished data products starting from raw data and are looking to improve your workflow </li>
<li> Are looking to expand your knowledge of Posit open source and professional tools </li>
<li> Want to improve interoperability between data products in your work or on your team </li>
<li> Have experience developing in R. An analogous course with a Python focus is also offered. </li>
<br><br>

**Speaker name:** Ryan Johnson
**Job title:** Data Science Advisor
**Company:** Posit, PBC
**Bio:**
Ryan is a Data Science Advisor at Posit with a background in Microbiology and Bioinformatics. He obtained his Ph.D. from the Uniformed Services University in Maryland and did his postdoctoral training at the National Human Genome Research Institute, NIH. In his current role, Ryan serves as a data science advocate and hosts workshops and webinars for teams across the globe."
Workshop,Data Talks: How to make your data science accessible,"## Title: Data Talks: How to make your data science accessible
**Code:** WS-016
**Session type:** Workshop

**Abstract:**
Data insights won’t speak for themselves. 
<br><br>
For the past five years, Articulation has been coaching all of the breakout session, keynote, and lightning talk speakers at posit::conf. We’ve heard time and again that the final leg of the data journey, communicating your data insights, is incredibly difficult. Being able to speak about your insights with clarity to non-data stakeholders can be the difference between your hard work leading to change and action or leading nowhere at all. 
<br><br>
This workshop is not about dashboards or visualization. It’s about what you say and how your audience hears you. 
<br><br>
The Promise: In this highly interactive, NO CODE workshop, you will work with your peers to learn how to frame your insights so that stakeholders with varying levels of understanding will listen. From determining what data you need to share, to helping your audience ask the right questions, to using storytelling to ensure they connect, you’ll enhance your ability to communicate your work with clarity, concision, and confidence.
<br>
What you’ll learn:
<ul>
<li> What data to gather about your audience </li>
<li> A formula for setting the necessary context </li>
<li> A formula for creating a bottom-line action-oriented one-sentence statement </li>
<li> Strategies for when to use data and when to use story and metaphor </li>
<li> Strategies for laddering complex insights </li>
</ul>
Who it’s for: You’re a mid-senior-level leader who needs to translate complex insights into actionable communications. You often find yourself presenting to non-data colleagues (C-Suite, HR, Sales, Finance, etc.). Your data skills are top-notch, and you want to make a bigger impact by improving your data communication. 
<br>
<br>
About Articulation: Articulation is more than just a public speaking training and executive coaching company. We see ourselves as a service to communities and organizations — large and small, public and private — that can help their executives and rising stars become better storytellers and better public speakers. Our clients come from Fortune 500 companies, internationally recognized education and research institutions, philanthropic organizations, and entrepreneurs eager to grow their businesses. Individuals from across the business spectrum also turn to us to obtain the presentation, public speaking, and storytelling skills to advance their careers and lead the people and companies they work for.

**Speaker name:** Blythe Coons
**Job title:** Executive Speech Coach
**Company:** Articulation
**Bio:**
Blythe Coons is a communications coach who loves helping clients uncover their powerful stories. She coaches cohorts of influential conference speakers, leads masterclasses to unlock clear, concise communication, and elevates individual clients to bring their best selves to important keynotes and presentations. At Articulation she is dedicated to helping others amplify their voices, connect authentically, and deliver messages that inspire action.

Across professional roles, Blythe has always been focused on clarifying complex messages. Armed with a BA from Haverford College and an MA from Middlebury College, she taught high school students English literature before completing an MFA in Acting. For a decade, Blythe connected with audiences from the stage in professional theaters throughout the U.S., including the American Shakespeare Center. 

Since returning to Columbus, Ohio, Blythe has served in leadership roles across steel fabrication, hospitality, and legal and financial services. She also devotes time to non-profit organizations that use storytelling to convey their mission.

Blythe enjoys baking the perfect treat for friends and family, running every morning, and hiking beautiful trails with her husband and two teenage step-children. 

## Title: Data Talks: How to make your data science accessible
**Code:** WS-016
**Session type:** Workshop

**Abstract:**
Data insights won’t speak for themselves. 
<br><br>
For the past five years, Articulation has been coaching all of the breakout session, keynote, and lightning talk speakers at posit::conf. We’ve heard time and again that the final leg of the data journey, communicating your data insights, is incredibly difficult. Being able to speak about your insights with clarity to non-data stakeholders can be the difference between your hard work leading to change and action or leading nowhere at all. 
<br><br>
This workshop is not about dashboards or visualization. It’s about what you say and how your audience hears you. 
<br><br>
The Promise: In this highly interactive, NO CODE workshop, you will work with your peers to learn how to frame your insights so that stakeholders with varying levels of understanding will listen. From determining what data you need to share, to helping your audience ask the right questions, to using storytelling to ensure they connect, you’ll enhance your ability to communicate your work with clarity, concision, and confidence.
<br>
What you’ll learn:
<ul>
<li> What data to gather about your audience </li>
<li> A formula for setting the necessary context </li>
<li> A formula for creating a bottom-line action-oriented one-sentence statement </li>
<li> Strategies for when to use data and when to use story and metaphor </li>
<li> Strategies for laddering complex insights </li>
</ul>
Who it’s for: You’re a mid-senior-level leader who needs to translate complex insights into actionable communications. You often find yourself presenting to non-data colleagues (C-Suite, HR, Sales, Finance, etc.). Your data skills are top-notch, and you want to make a bigger impact by improving your data communication. 
<br>
<br>
About Articulation: Articulation is more than just a public speaking training and executive coaching company. We see ourselves as a service to communities and organizations — large and small, public and private — that can help their executives and rising stars become better storytellers and better public speakers. Our clients come from Fortune 500 companies, internationally recognized education and research institutions, philanthropic organizations, and entrepreneurs eager to grow their businesses. Individuals from across the business spectrum also turn to us to obtain the presentation, public speaking, and storytelling skills to advance their careers and lead the people and companies they work for.

**Speaker name:** Acacia Duncan
**Job title:** Director of Coaching and Training
**Company:** Articulation
**Bio:**
Acacia Duncan trains speakers to captivate their audiences with purpose, precision, and passion. She helps leaders, CEOs, and experts to transform complex ideas into communications that shift perspectives and inspire action.
<br><br>
In one-on-one coaching, small group settings, and workshops for 400+ people, Acacia equips professionals with tools for communicating confidently and persuasively. She also elevates company cultures by creating innovative training programs for businesses.
<br><br>
In addition to being the Director of Coaching and Training at Articulation, Acacia is a founding Company Member of Available Light Theatre. She is a professional director and actor who has performed in over sixty plays and three feature films. Her decades of experience -- on stage and off -- have taught her how to bring out the creativity in every collaborator.
<br><br>
Before joining Articulation in 2016, Acacia spent 14 years as a corporate coach and trainer in the retail sector. She graduated from Miami University with degrees in Theatre Performance and Economics, studied at the London Academy of Music and Dramatic Arts, and received her coaching certification from Erickson Coaching International.  
<br><br>
Acacia lives in Columbus, Ohio with her husband, Matt Slaybaugh. She is a hiker, a baker, a dog lover, and a life long Trekkie."
Workshop,Deploying reproducible analytics environments for regulated use cases,"## Title: Deploying reproducible analytics environments for regulated use cases
**Code:** WS-015
**Session type:** Workshop

**Abstract:**
The deployment of reproducible analytical environments is a critical topic in the regulated industries, especially for meeting regulatory requirements and ensuring reproducibility in research. This workshop aims to explore the multifaceted challenges and opportunities associated with provisioning and deploying R-based environments, drawing from experiences of deploying enterprise-scale analytical environments for regulatory filings. 
<br><br>
Our session will address the following key questions and themes:
<ul>
<li> Actionability of Containers for R Deployments: Evaluating the feasibility and effectiveness of using containers to deploy R-based environments for clinical and regulatory use. The discussion will include scaling with clinical use cases and polyglot analyses. </li>
<li> Industry-Standard Base Images: Consider whether and how a standard industry base image could streamline health authority buy-in and compliance processes. </li>
<li> Selecting Packages: Identifying essential qualities to assess for package selection, discussing the categorization of risk and respective activities for high-risk uses. </li>
<li> Pharma-Specific Package Testing: Debating the necessity for pharma-specific testing of public packages and envisioning potential shared solutions for package validation and vulnerability tracking. </li>
<li> Does this align with a path to sharing environments with regulators: Examining the practicality of sharing containerized analyses with health authorities, taking into account OS differences? </li>
<li> Compliance with the EU Cybersecurity Resilience Act: Outlining expectations and requirements for public R repositories to support compliance with recent cybersecurity legislation. </li>
<li> Provisioning packages to users: Historically, there is a preference to bundle packages into an environment rather than use a repository snapshot. Using learnings from companies that have de-coupled R packages from operating systems, how can we balance the burden of validation and qualification against the need for open source to be able to deploy packages continuously and empower teams with the agility to move between more granular package cohorts snapshots? </li>
</ul>
<br>
The workshop will blend insight from those who have navigated these challenges with discussions on current solutions and methodologies. Our goal is to foster a community dialogue that highlights existing implementations and explores diverse perspectives without imposing a single opinionated process. This workshop will be a mixture of sharing, discussion, and exercises.
<br><br>
Join us for a robust discussion to share experiences, identify best practices, and contribute to a collective understanding of deploying validated R packages in a compliant and efficient manner within highly regulated industries.
<br><br>
Target Audience: This workshop is ideal for data scientists, statisticians, IT professionals, and regulatory compliance experts interested in deploying R packages in highly regulated environments.

**Speaker name:** James Black
**Job title:** Executive Director, Technology and Scientific Computing
**Company:** Novartis
**Bio:**
James Black, Executive Director at Novartis is business lead for the development of the next generation Scientific Computing Environment, as a member of Technology & Scientific Computing in Advanced Quantitative Sciences.

## Title: Deploying reproducible analytics environments for regulated use cases
**Code:** WS-015
**Session type:** Workshop

**Abstract:**
The deployment of reproducible analytical environments is a critical topic in the regulated industries, especially for meeting regulatory requirements and ensuring reproducibility in research. This workshop aims to explore the multifaceted challenges and opportunities associated with provisioning and deploying R-based environments, drawing from experiences of deploying enterprise-scale analytical environments for regulatory filings. 
<br><br>
Our session will address the following key questions and themes:
<ul>
<li> Actionability of Containers for R Deployments: Evaluating the feasibility and effectiveness of using containers to deploy R-based environments for clinical and regulatory use. The discussion will include scaling with clinical use cases and polyglot analyses. </li>
<li> Industry-Standard Base Images: Consider whether and how a standard industry base image could streamline health authority buy-in and compliance processes. </li>
<li> Selecting Packages: Identifying essential qualities to assess for package selection, discussing the categorization of risk and respective activities for high-risk uses. </li>
<li> Pharma-Specific Package Testing: Debating the necessity for pharma-specific testing of public packages and envisioning potential shared solutions for package validation and vulnerability tracking. </li>
<li> Does this align with a path to sharing environments with regulators: Examining the practicality of sharing containerized analyses with health authorities, taking into account OS differences? </li>
<li> Compliance with the EU Cybersecurity Resilience Act: Outlining expectations and requirements for public R repositories to support compliance with recent cybersecurity legislation. </li>
<li> Provisioning packages to users: Historically, there is a preference to bundle packages into an environment rather than use a repository snapshot. Using learnings from companies that have de-coupled R packages from operating systems, how can we balance the burden of validation and qualification against the need for open source to be able to deploy packages continuously and empower teams with the agility to move between more granular package cohorts snapshots? </li>
</ul>
<br>
The workshop will blend insight from those who have navigated these challenges with discussions on current solutions and methodologies. Our goal is to foster a community dialogue that highlights existing implementations and explores diverse perspectives without imposing a single opinionated process. This workshop will be a mixture of sharing, discussion, and exercises.
<br><br>
Join us for a robust discussion to share experiences, identify best practices, and contribute to a collective understanding of deploying validated R packages in a compliant and efficient manner within highly regulated industries.
<br><br>
Target Audience: This workshop is ideal for data scientists, statisticians, IT professionals, and regulatory compliance experts interested in deploying R packages in highly regulated environments.

**Speaker name:** Orla Doyle
**Job title:** Data Scientist
**Company:** Novartis
**Bio:**
Orla Doyle is a Data Science Director at Novartis. Her role is in the Analytics, Computing and Engineering team where she focuses on enabling the use of open-source tooling in clinical trial analysis and reporting. Prior to joining Novartis, she was part of the Predictive Analytics team at IQVIA working on interpretable machine learning models for applications such as rare disease detection in real-world data. Orla has also spent time in academia. She earned her PhD from University College Cork on the use of signal processing and machine learning for neonatal monitoring. She has held Postdoctoral Fellowships at King's College London where she developed machine learning models for brain imaging data. 

## Title: Deploying reproducible analytics environments for regulated use cases
**Code:** WS-015
**Session type:** Workshop

**Abstract:**
The deployment of reproducible analytical environments is a critical topic in the regulated industries, especially for meeting regulatory requirements and ensuring reproducibility in research. This workshop aims to explore the multifaceted challenges and opportunities associated with provisioning and deploying R-based environments, drawing from experiences of deploying enterprise-scale analytical environments for regulatory filings. 
<br><br>
Our session will address the following key questions and themes:
<ul>
<li> Actionability of Containers for R Deployments: Evaluating the feasibility and effectiveness of using containers to deploy R-based environments for clinical and regulatory use. The discussion will include scaling with clinical use cases and polyglot analyses. </li>
<li> Industry-Standard Base Images: Consider whether and how a standard industry base image could streamline health authority buy-in and compliance processes. </li>
<li> Selecting Packages: Identifying essential qualities to assess for package selection, discussing the categorization of risk and respective activities for high-risk uses. </li>
<li> Pharma-Specific Package Testing: Debating the necessity for pharma-specific testing of public packages and envisioning potential shared solutions for package validation and vulnerability tracking. </li>
<li> Does this align with a path to sharing environments with regulators: Examining the practicality of sharing containerized analyses with health authorities, taking into account OS differences? </li>
<li> Compliance with the EU Cybersecurity Resilience Act: Outlining expectations and requirements for public R repositories to support compliance with recent cybersecurity legislation. </li>
<li> Provisioning packages to users: Historically, there is a preference to bundle packages into an environment rather than use a repository snapshot. Using learnings from companies that have de-coupled R packages from operating systems, how can we balance the burden of validation and qualification against the need for open source to be able to deploy packages continuously and empower teams with the agility to move between more granular package cohorts snapshots? </li>
</ul>
<br>
The workshop will blend insight from those who have navigated these challenges with discussions on current solutions and methodologies. Our goal is to foster a community dialogue that highlights existing implementations and explores diverse perspectives without imposing a single opinionated process. This workshop will be a mixture of sharing, discussion, and exercises.
<br><br>
Join us for a robust discussion to share experiences, identify best practices, and contribute to a collective understanding of deploying validated R packages in a compliant and efficient manner within highly regulated industries.
<br><br>
Target Audience: This workshop is ideal for data scientists, statisticians, IT professionals, and regulatory compliance experts interested in deploying R packages in highly regulated environments.

**Speaker name:** Doug Kelkhoff
**Job title:** Data Scientist
**Company:** Roche
**Bio:**
NA

## Title: Deploying reproducible analytics environments for regulated use cases
**Code:** WS-015
**Session type:** Workshop

**Abstract:**
The deployment of reproducible analytical environments is a critical topic in the regulated industries, especially for meeting regulatory requirements and ensuring reproducibility in research. This workshop aims to explore the multifaceted challenges and opportunities associated with provisioning and deploying R-based environments, drawing from experiences of deploying enterprise-scale analytical environments for regulatory filings. 
<br><br>
Our session will address the following key questions and themes:
<ul>
<li> Actionability of Containers for R Deployments: Evaluating the feasibility and effectiveness of using containers to deploy R-based environments for clinical and regulatory use. The discussion will include scaling with clinical use cases and polyglot analyses. </li>
<li> Industry-Standard Base Images: Consider whether and how a standard industry base image could streamline health authority buy-in and compliance processes. </li>
<li> Selecting Packages: Identifying essential qualities to assess for package selection, discussing the categorization of risk and respective activities for high-risk uses. </li>
<li> Pharma-Specific Package Testing: Debating the necessity for pharma-specific testing of public packages and envisioning potential shared solutions for package validation and vulnerability tracking. </li>
<li> Does this align with a path to sharing environments with regulators: Examining the practicality of sharing containerized analyses with health authorities, taking into account OS differences? </li>
<li> Compliance with the EU Cybersecurity Resilience Act: Outlining expectations and requirements for public R repositories to support compliance with recent cybersecurity legislation. </li>
<li> Provisioning packages to users: Historically, there is a preference to bundle packages into an environment rather than use a repository snapshot. Using learnings from companies that have de-coupled R packages from operating systems, how can we balance the burden of validation and qualification against the need for open source to be able to deploy packages continuously and empower teams with the agility to move between more granular package cohorts snapshots? </li>
</ul>
<br>
The workshop will blend insight from those who have navigated these challenges with discussions on current solutions and methodologies. Our goal is to foster a community dialogue that highlights existing implementations and explores diverse perspectives without imposing a single opinionated process. This workshop will be a mixture of sharing, discussion, and exercises.
<br><br>
Join us for a robust discussion to share experiences, identify best practices, and contribute to a collective understanding of deploying validated R packages in a compliant and efficient manner within highly regulated industries.
<br><br>
Target Audience: This workshop is ideal for data scientists, statisticians, IT professionals, and regulatory compliance experts interested in deploying R packages in highly regulated environments.

**Speaker name:** Michael Mayer
**Job title:** Principal Solution Engineer
**Company:** Posit
**Bio:**
NA

## Title: Deploying reproducible analytics environments for regulated use cases
**Code:** WS-015
**Session type:** Workshop

**Abstract:**
The deployment of reproducible analytical environments is a critical topic in the regulated industries, especially for meeting regulatory requirements and ensuring reproducibility in research. This workshop aims to explore the multifaceted challenges and opportunities associated with provisioning and deploying R-based environments, drawing from experiences of deploying enterprise-scale analytical environments for regulatory filings. 
<br><br>
Our session will address the following key questions and themes:
<ul>
<li> Actionability of Containers for R Deployments: Evaluating the feasibility and effectiveness of using containers to deploy R-based environments for clinical and regulatory use. The discussion will include scaling with clinical use cases and polyglot analyses. </li>
<li> Industry-Standard Base Images: Consider whether and how a standard industry base image could streamline health authority buy-in and compliance processes. </li>
<li> Selecting Packages: Identifying essential qualities to assess for package selection, discussing the categorization of risk and respective activities for high-risk uses. </li>
<li> Pharma-Specific Package Testing: Debating the necessity for pharma-specific testing of public packages and envisioning potential shared solutions for package validation and vulnerability tracking. </li>
<li> Does this align with a path to sharing environments with regulators: Examining the practicality of sharing containerized analyses with health authorities, taking into account OS differences? </li>
<li> Compliance with the EU Cybersecurity Resilience Act: Outlining expectations and requirements for public R repositories to support compliance with recent cybersecurity legislation. </li>
<li> Provisioning packages to users: Historically, there is a preference to bundle packages into an environment rather than use a repository snapshot. Using learnings from companies that have de-coupled R packages from operating systems, how can we balance the burden of validation and qualification against the need for open source to be able to deploy packages continuously and empower teams with the agility to move between more granular package cohorts snapshots? </li>
</ul>
<br>
The workshop will blend insight from those who have navigated these challenges with discussions on current solutions and methodologies. Our goal is to foster a community dialogue that highlights existing implementations and explores diverse perspectives without imposing a single opinionated process. This workshop will be a mixture of sharing, discussion, and exercises.
<br><br>
Join us for a robust discussion to share experiences, identify best practices, and contribute to a collective understanding of deploying validated R packages in a compliant and efficient manner within highly regulated industries.
<br><br>
Target Audience: This workshop is ideal for data scientists, statisticians, IT professionals, and regulatory compliance experts interested in deploying R packages in highly regulated environments.

**Speaker name:** Rafael Pereira
**Job title:** President
**Company:** Appsilon
**Bio:**
NA"
Workshop,End-to-End Submissions in R with the Pharmaverse,"## Title: End-to-End Submissions in R with the Pharmaverse
**Code:** WS-014
**Session type:** Workshop

**Abstract:**
Ready to optimize your regulatory submission process? This workshop offers a practical, end-to-end introduction to using R for a streamlined workflow from raw data to tables, listings, and graphs (TLGs). We'll dive into the power of key R packages from the Pharmaverse, starting with SDTM data preparation; learn to effortlessly map, transform, and validate your data to CDISC standards, ensuring both quality and compliance. Next, create ADaM datasets using modular and pipe-able syntax. Finally, get ready to generate compelling TLGs supported by Analysis Results Datasets (ARDs). We'll explore techniques for producing publication-ready output, customized to meet your specific reporting needs. Walk away with the skills to confidently use R for every stage of the submission process.

**Speaker name:** Becca Krouse
**Job title:** Data Science Leader
**Company:** GSK
**Bio:**
Becca Krouse is a data scientist in GSK's Statistics and Data Science Innovation Hub. A biostatistician by training, she has experience spanning 13+ years in the field of clinical research and specializes in developing R-based tools.

## Title: End-to-End Submissions in R with the Pharmaverse
**Code:** WS-014
**Session type:** Workshop

**Abstract:**
Ready to optimize your regulatory submission process? This workshop offers a practical, end-to-end introduction to using R for a streamlined workflow from raw data to tables, listings, and graphs (TLGs). We'll dive into the power of key R packages from the Pharmaverse, starting with SDTM data preparation; learn to effortlessly map, transform, and validate your data to CDISC standards, ensuring both quality and compliance. Next, create ADaM datasets using modular and pipe-able syntax. Finally, get ready to generate compelling TLGs supported by Analysis Results Datasets (ARDs). We'll explore techniques for producing publication-ready output, customized to meet your specific reporting needs. Walk away with the skills to confidently use R for every stage of the submission process.

**Speaker name:** Daniel Sjoberg
**Job title:** Senior Principal Data Scientist
**Company:** Genentech
**Bio:**
Daniel D. Sjoberg (he/him) is a Senior Principal Data Scientist at Genentech. Previously, he was a Lead Data Science Manager at the Prostate Cancer Clinical Trials Consortium, and a Senior Biostatistician at Memorial Sloan Kettering Cancer Center in New York City. He enjoys R package development, creating many packages available on CRAN, R-Universe, and GitHub. He is the primary author of two pharmaverse packages, and has contributed to others. Daniel is the winner of the 2021 American Statistical Association (ASA) Innovation in Statistical Programming and Analytics award."
Workshop,Exploratory Data Analysis with Python Polars,"## Title: Exploratory Data Analysis with Python Polars
**Code:** WS-018
**Session type:** Workshop

**Abstract:**
Join us for a hands-on workshop focused on Polars, a high-performance data processing package for Python. We’ll dive into Polars’ powerful features and show you how to use it for real-world tasks like data wrangling, exploratory data analysis, and building pipelines. Whether you’re new to Polars or looking to transition from other packages like pandas, this workshop will help you quickly master its expressive API and underlying concepts.
<br><br>
You’ll learn how to:
<ul>
<li> Efficiently process data from various sources like CSV, Parquet, and spreadsheets </li>
<li> Get a solid understanding of expressions, the building blocks of every query </li>
<li> Utilize Polars' eager and lazy APIs, understanding when to apply each </li>
<li> Work with complex data types, including time, text, and nested structures </li>
<li> Visualize DataFrames with packages like Altair, plotnine, and Great Tables </li>
</ul>
<br>
This workshop is ideal for data scientists and data engineers looking to enhance their workflows and improve performance at scale. By the end, you’ll understand why everybody says: Polars come for the speed, stay for the syntax.

**Speaker name:** Jeroen Janssens
**Job title:** 
**Company:** Posit
**Bio:**
NA"
Workshop,Extending Quarto,"## Title: Extending Quarto
**Code:** WS-005
**Session type:** Workshop

**Abstract:**
In this workshop, we will dive deep into ways of customizing your Quarto outputs with tooling beyond built-in features. This workshop is designed for data scientists, analysts, and technical writers looking to extend Quarto's capabilities to suit their unique workflows better.
<br><br>
Participants will learn how to create custom extensions, including new formats, templates, and filters, to enhance their document production process. Through hands-on exercises and real-world examples, you'll gain practical skills in:
<br>
<li> Developing and integrating custom formats to support diverse outputs while reducing repetition across projects. </li>
<li> Substituting Quarto's templates with your own to customize formats beyond the built-in options. </li>
<li> Implementing filters to automate and streamline content transformation. </li>
<br><br>
By the end of the workshop, you will be able to leverage Quarto's extensibility to create powerful, tailored solutions for your documentation needs. Whether you have just worked on a few Quarto projects or are an everyday user, this workshop will equip you with the tools and knowledge to take your document workflows to the next level.
<br><br>

**Speaker name:** Mine Cetinkaya-Rundel
**Job title:** Professor + Developer Educator
**Company:** Posit
**Bio:**
<p><a href=""http://mine-cr.com/"" target=""_blank""><strong>Dr. Mine Çetinkaya-Rundel</strong></a> (she/her) is Professor of the Practice at Duke University and Developer Educator at Posit. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine works on integrating computation into the undergraduate statistics curriculum, using reproducible research methodologies and analysis of real and complex datasets. Mine works on the OpenIntro project, whose mission is to make educational products that are free, transparent, and lower barriers to education. As part of this project she co-authored four open-source introductory statistics textbooks. She is also the creator and maintainer of datasciencebox.org and she teaches the popular Statistics with R MOOC on Coursera. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for Excellence in Teaching Introductory Statistics.</p>

## Title: Extending Quarto
**Code:** WS-005
**Session type:** Workshop

**Abstract:**
In this workshop, we will dive deep into ways of customizing your Quarto outputs with tooling beyond built-in features. This workshop is designed for data scientists, analysts, and technical writers looking to extend Quarto's capabilities to suit their unique workflows better.
<br><br>
Participants will learn how to create custom extensions, including new formats, templates, and filters, to enhance their document production process. Through hands-on exercises and real-world examples, you'll gain practical skills in:
<br>
<li> Developing and integrating custom formats to support diverse outputs while reducing repetition across projects. </li>
<li> Substituting Quarto's templates with your own to customize formats beyond the built-in options. </li>
<li> Implementing filters to automate and streamline content transformation. </li>
<br><br>
By the end of the workshop, you will be able to leverage Quarto's extensibility to create powerful, tailored solutions for your documentation needs. Whether you have just worked on a few Quarto projects or are an everyday user, this workshop will equip you with the tools and knowledge to take your document workflows to the next level.
<br><br>

**Speaker name:** Charlotte Wickham
**Job title:** Developer Educator
**Company:** Posit
**Bio:**
<p><a href=""http://cwick.co.nz/"" target=""_blank""><strong>Dr. Charlotte Wickham</strong></a> (she/her) is a Developer Educator at Posit. As part of her job at Posit, Charlotte helps to keep <a href=""https://quarto.org/"" target=""_blank"">quarto.org</a>—a website about, and also built with, Quarto—up to date. Prior to Posit, she taught Statistics and Data Science at Oregon State University where she received awards for her in-person and online teaching.</p>"
Workshop,From R User to R Programmer,"## Title: From R User to R Programmer
**Code:** WS-010
**Session type:** Workshop

**Abstract:**
This is a one-day, hands-on workshop for intermediate R users who use the tidyverse and want to improve and reduce the amount of duplication in their code. You will learn the two main ways to reduce duplication: creating functions and using iteration.
<br><br>
We will use a tidyverse approach to cover function design and iteration. When writing a function, you will learn how to deal with “data masking,” give default values to arguments, give unspecified arguments, and what side effects are and how to manage them. In the afternoon, you will learn how to iterate across the columns of a data frame using across(), what “anonymous” functions are, and how to read and write multiple files using purrr.
<br><br>
This course is for you if you:
<ul>
<li> have experience equivalent to an introductory data science course using tidyverse</li>
<li> feel comfortable with the Whole game part of R for Data Science</li>
<li> want to learn how to write functions and use iteration to reduce duplication in your code</li>
</ul>
<br><br>

**Speaker name:** Emma Rand
**Job title:** Professor
**Company:** University of York
**Bio:**
Emma Rand is a Senior Lecturer in the Department of Biology at the University of York where she specializes in teaching data science and reproducibility, particularly to those who do not see themselves as programmers. She leads a UKRI funded project called Cloud-SPAN which trains researchers in cloud-based high performance computing for ’omics. She is a Software Sustainability Institute Fellow, a Teaching team lead for R Forwards and delivers data science training for the Royal Society of Biology and the Biochemical Society.

## Title: From R User to R Programmer
**Code:** WS-010
**Session type:** Workshop

**Abstract:**
This is a one-day, hands-on workshop for intermediate R users who use the tidyverse and want to improve and reduce the amount of duplication in their code. You will learn the two main ways to reduce duplication: creating functions and using iteration.
<br><br>
We will use a tidyverse approach to cover function design and iteration. When writing a function, you will learn how to deal with “data masking,” give default values to arguments, give unspecified arguments, and what side effects are and how to manage them. In the afternoon, you will learn how to iterate across the columns of a data frame using across(), what “anonymous” functions are, and how to read and write multiple files using purrr.
<br><br>
This course is for you if you:
<ul>
<li> have experience equivalent to an introductory data science course using tidyverse</li>
<li> feel comfortable with the Whole game part of R for Data Science</li>
<li> want to learn how to write functions and use iteration to reduce duplication in your code</li>
</ul>
<br><br>

**Speaker name:** Ian Lyttle
**Job title:** Data Scientist
**Company:** Schneider Electric
**Bio:**
Ian Lyttle is a Data Scientist at Schneider Electric. His technical interests include visualization, interactivity, and functional programming. He is a community contributor to tidyverse and r-lib, and maintains CRAN packages including {vegawidget} and {boxr}. He has delivered tutorials on a variety of R topics at posit::conf(), UseR!, Uncoast Unconf, and the Iowa State University Graphics Group."
Workshop,Getting More Out of Feature Engineering and Tuning for Machine Learning,"## Title: Getting More Out of Feature Engineering and Tuning for Machine Learning
**Code:** WS-004
**Session type:** Workshop

**Abstract:**
In this workshop, you will learn more advanced methods for building better models.
<br><br>
Feature engineering is a method of representing your data in a way that makes the model work best. We’ll talk about how to use recipes to engineer features and a few specific methods, such as splines for nonlinear features and effect encodings for high cardinality predictors. We’ll also show how to optimize model performance by choosing the best tuning parameters. The focus is on grid search and hyper-efficient racing methods. Time permitting, we’ll also discuss the simultaneous evaluation of many combinations of pre-processors, models, and post-processors using workflow sets.
<br><br>
This course is focused on the analysis of tabular data and does not include deep learning methods.
<br><br>

**Speaker name:** Max Kuhn
**Job title:** Principal Software Engineer
**Company:** Posit
**Bio:**
Max Kuhn is a software engineer at Posit PBC (nee RStudio). He is improving R’s modeling capabilities and maintaining about 30 packages, including caret. He was a Senior Director of Nonclinical Statistics at Pfizer Global R&D in Connecticut. He has applied models in the pharmaceutical and diagnostic industries for over 18 years. Max has a Ph.D. in Biostatistics.  He and Kjell Johnson wrote the book Applied Predictive Modeling, which won the Ziegel award from the American Statistical Association, recognizing the best book reviewed in Technometrics in 2015. He has co-written several other books: Feature Engineering and Selection, Tidy Models with R, and Applied Machine Learning for Tabular Data (in process). 


## Title: Getting More Out of Feature Engineering and Tuning for Machine Learning
**Code:** WS-004
**Session type:** Workshop

**Abstract:**
In this workshop, you will learn more advanced methods for building better models.
<br><br>
Feature engineering is a method of representing your data in a way that makes the model work best. We’ll talk about how to use recipes to engineer features and a few specific methods, such as splines for nonlinear features and effect encodings for high cardinality predictors. We’ll also show how to optimize model performance by choosing the best tuning parameters. The focus is on grid search and hyper-efficient racing methods. Time permitting, we’ll also discuss the simultaneous evaluation of many combinations of pre-processors, models, and post-processors using workflow sets.
<br><br>
This course is focused on the analysis of tabular data and does not include deep learning methods.
<br><br>

**Speaker name:** Emil Hvitfeldt
**Job title:** Software Engineer
**Company:** Posit PBC
**Bio:**
Emil Hvitfeldt is a software engineer at Posit and part of the tidymodels team’s effort to improve R’s modeling capabilities. He maintains several packages within the realms of modeling, text analysis, and color palettes. Trying to make slidecrafting a well respecting verb. He co-authored the book Supervised Machine Learning for Text Analysis in R with Julia Silge. Working on book Feature Engineering A-Z."
Workshop,Introduction to machine learning in R with tidymodels,"## Title: Introduction to machine learning in R with tidymodels
**Code:** WS-002
**Session type:** Workshop

**Abstract:**
This workshop will teach you the fundamentals of predictive modeling with core tidymodels packages: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and model optimization using the tune package. Time permitting, you'll be introduced to basic pre-processing with recipes. 
<br><br>
In this workshop, you'll learn the process of predictive modeling for tabular data and tidymodels syntax to put it into practice.
<br><br>

**Speaker name:** Hannah Frick
**Job title:** Senior Software Engineer
**Company:** Posit
**Bio:**
Hannah Frick is a software engineer on the tidymodels team at Posit. She holds a PhD in statistics and has worked in interdisciplinary research and data science consultancy. She is a co-founder of R-Ladies Global.

## Title: Introduction to machine learning in R with tidymodels
**Code:** WS-002
**Session type:** Workshop

**Abstract:**
This workshop will teach you the fundamentals of predictive modeling with core tidymodels packages: data splitting/resampling with rsample, model fitting with parsnip, measuring model performance with yardstick, and model optimization using the tune package. Time permitting, you'll be introduced to basic pre-processing with recipes. 
<br><br>
In this workshop, you'll learn the process of predictive modeling for tabular data and tidymodels syntax to put it into practice.
<br><br>

**Speaker name:** Simon P. Couch
**Job title:** Software Engineer
**Company:** Posit, PBC
**Bio:**
Simon Couch is a software engineer at Posit PBC where he works on open source statistical software. With an academic background in statistics and sociology, Simon believes that principled tooling has a profound impact on our ability to think rigorously about data. He authors and maintains a number of R packages and blogs about the process at simonpcouch.com. "
Workshop,Machine learning with scikit-learn in Python,"## Title: Machine learning with scikit-learn in Python
**Code:** WS-009
**Session type:** Workshop

**Abstract:**
This workshop will teach you how to perform machine learning for prediction in Python using the widely-used Scikit-learn learn package. You will be introduced to best practices for machine learning model creation and selection, including data splitting, pre-processing, parameter and model optimization, as well as results visualization and communication. Workshop examples will begin with simple, intuitive models (e.g., K-nearest neighbors, linear regression) but also demonstrate the use of more commonly used and industry standard models (e.g., ensemble methods such as random forest and boosting). The workshop will focus on demonstrating how to do this using the modern Scikit-learn pipeline syntax.

**Speaker name:** Tiffany Timbers
**Job title:** Associate Professor of Teaching
**Company:** University of British Columbia
**Bio:**
<p><u><a href=""https://www.tiffanytimbers.com/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Tiffany Timbers</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;""> is an Associate Professor of Teaching in the Department of Statistics and Co-Director for the Master of Data Science program (Vancouver Option) at the University of British Columbia. In these roles she teaches and develops curriculum around the responsible application of Data Science to solve real-world problems. One of her favorite courses she teaches is a graduate course on collaborative software development, which focuses on teaching how to create R and Python packages using modern tools and workflows. She is an author of </span><u><a href=""https://python.datasciencebook.ca/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Data Science: A First Introduction</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;""> - a textbook that serves as an approachable introduction to the world of data science, written now in both </span><u><a href=""https://python.datasciencebook.ca/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">R</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;""> and </span><u><a href=""https://datasciencebook.ca/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Python</a>.</u></p>

## Title: Machine learning with scikit-learn in Python
**Code:** WS-009
**Session type:** Workshop

**Abstract:**
This workshop will teach you how to perform machine learning for prediction in Python using the widely-used Scikit-learn learn package. You will be introduced to best practices for machine learning model creation and selection, including data splitting, pre-processing, parameter and model optimization, as well as results visualization and communication. Workshop examples will begin with simple, intuitive models (e.g., K-nearest neighbors, linear regression) but also demonstrate the use of more commonly used and industry standard models (e.g., ensemble methods such as random forest and boosting). The workshop will focus on demonstrating how to do this using the modern Scikit-learn pipeline syntax.

**Speaker name:** Katie Burak
**Job title:** Assistant Professor of Teaching
**Company:** University of British Columbia
**Bio:**
I am an Assistant Professor of Teaching in the Department of Statistics as well as a member of the academic team for the Master of Data Science Program at the University of British Columbia. My work focuses on modern pedagogical methods in statistics and data science. I am passionate about academic outreach, with a focus on promoting women in data science and addressing equity issues in the statistical sciences."
Workshop,Mastering Data Visualization with ggplot2: Latest Techniques and Best Practices,"## Title: Mastering Data Visualization with ggplot2: Latest Techniques and Best Practices
**Code:** WS-007
**Session type:** Workshop

**Abstract:**
This workshop will explore the cutting-edge advancements and best practices in data visualization using ggplot2. This workshop is designed for data enthusiasts, analysts, and researchers who are eager to elevate their visual data storytelling skills. This workshop will be relevant to both ggplot2 users as well as package authors that somehow extend ggplot2 in their packages.
<br><br>
Throughout the day, participants will:
<br>
<li> Discover the Latest Features: ggplot2 and its ecosystem is ever-evolving. We will cover all the new features of ggplot2 itself and highlight key features from important extension packages, so you can rest assured that no new features have escaped your attention. </li>
<li> Advanced Customization Techniques: Dive deep into how to manage and control the looks of your visualisation in order to create visually stunning and informative plots. </li>
<li> Understand text and fonts: Text is an indispensable part of data visualisation, yet rendering of it, especially when using custom fonts, is somewhat mysterious. Learn exactly what is going on so you can be confident in using text to the fullest </li>
<li> Multifigure Plot Compositions: Utilize the latest features of patchwork to create complex plot layouts, including native support for gt tables and improved handling of plot components across multiple grid cells. </li>
<br><br>
By the end of this workshop, you'll have a comprehensive understanding of the latest tools and techniques in ggplot2, empowering you to create compelling and insightful data visualizations. Whether you're a user or a package developer, this workshop will provide valuable insights and skills to enhance your data visualization toolkit.
<br><br>

**Speaker name:** Thomas Lin Lin Pedersen
**Job title:** Software Engineer
**Company:** Posit
**Bio:**
Thomas Lin Pedersen is a software engineer in the Tidyverse team at Posit. He spends most of his time taking care of the graphics stack in R from maintaining high-level packages such as ggplot2 and patchwork, all the way down to developing and maintaining graphics devices like ragg and svglite.

## Title: Mastering Data Visualization with ggplot2: Latest Techniques and Best Practices
**Code:** WS-007
**Session type:** Workshop

**Abstract:**
This workshop will explore the cutting-edge advancements and best practices in data visualization using ggplot2. This workshop is designed for data enthusiasts, analysts, and researchers who are eager to elevate their visual data storytelling skills. This workshop will be relevant to both ggplot2 users as well as package authors that somehow extend ggplot2 in their packages.
<br><br>
Throughout the day, participants will:
<br>
<li> Discover the Latest Features: ggplot2 and its ecosystem is ever-evolving. We will cover all the new features of ggplot2 itself and highlight key features from important extension packages, so you can rest assured that no new features have escaped your attention. </li>
<li> Advanced Customization Techniques: Dive deep into how to manage and control the looks of your visualisation in order to create visually stunning and informative plots. </li>
<li> Understand text and fonts: Text is an indispensable part of data visualisation, yet rendering of it, especially when using custom fonts, is somewhat mysterious. Learn exactly what is going on so you can be confident in using text to the fullest </li>
<li> Multifigure Plot Compositions: Utilize the latest features of patchwork to create complex plot layouts, including native support for gt tables and improved handling of plot components across multiple grid cells. </li>
<br><br>
By the end of this workshop, you'll have a comprehensive understanding of the latest tools and techniques in ggplot2, empowering you to create compelling and insightful data visualizations. Whether you're a user or a package developer, this workshop will provide valuable insights and skills to enhance your data visualization toolkit.
<br><br>

**Speaker name:** Teun Van den Brand
**Job title:** 
**Company:** Posit
**Bio:**
NA"
Workshop,Modern Data Platforms with Posit for R & Python Users,"## Title: Modern Data Platforms with Posit for R & Python Users
**Code:** WS-012
**Session type:** Workshop

**Abstract:**
As organizations increasingly rely on scalable cloud and database solutions, data practitioners must seamlessly integrate R and Python workflows with modern data platforms. This hands-on workshop will teach participants how to leverage Posit’s suite of open-source and commercial tools to efficiently connect, analyze, and deploy insights using Snowflake, Databricks, and DuckDB.
<br><br>
Through practical examples and live coding, attendees will learn:
<ul>
<li> How to integrate R and Python with Snowflake, Databricks, and DuckDB for seamless data access and transformation. </li>
<li> Best practices for querying, transforming, and analyzing data, along with strategies for optimizing performance and scalability in data-intensive applications. </li>
<li> How to streamline development and deployment using Posit Workbench, Connect, and Package Manager with these data platforms. </li>
<li> How to leverage GenAI models provided by modern data platforms to enhance data workflows and insights. </li>
</ul>
<br>
This workshop is designed for data scientists, analysts, and engineers using R or Python who want to enhance their workflows with cloud and database platforms. By the end of this workshop, participants will have a solid foundation in using Posit tools to work with enterprise-scale data solutions—empowering them to build, share, and deploy insights faster.

**Speaker name:** James Blair
**Job title:** Senior Product Manager
**Company:** Posit
**Bio:**
James is a Senior Product Manager at Posit, where he focuses on helping Posit commercial products seamlessly integrate into cloud environments. He has a background in statistics and data science and finds any excuse he can to write R code and ride his bike, although usually not at the same time."
Workshop,Package Development: The Rest of the Owl,"## Title: Package Development: The Rest of the Owl
**Code:** WS-006
**Session type:** Workshop

**Abstract:**
In R, the fundamental unit of reusable and shareable code is a package containing helpful functions, documentation, and sometimes sample data.
Putting R code in a package is the best way to share our code with others or to share code across different projects.<br><br>
This workshop assumes you've already dipped your toe in package development, i.e. that you've managed to create a basic package and pass `R CMD check`.
In terms of ""How to draw an owl"", you've definitely drawn some circles.<br><br>
But now it's time to draw the <a href=""https://datasciencebox.org/images/design-owl.jpg""><b><u>rest of the owl</u></b></a>!
<br><br>You will learn workflows and skills that are (a) very important for package development and (b) very different from writing R scripts.
We will lean heavily on the tools and principles used by the tidyverse team, embodied in the devtools family of packages, including usethis, testthat, and roxygen2.
<br><br>
This list of topics is indicative of what we will cover:
<ul>
<li>   Fundamental daily workflows: `devtools::load_all()` and `check()`</li>
<li>   Self-help: the power of GitHub code search and small experiments</li>
<li>   Testing: the testthat package and the philosophy of writing tests as you go (vs. ""later"")</li>
<li>   Documentation: function documentation, vignettes, and website</li>
<li>   Data: internal data vs. data available to your user</li>
<li>   GitHub Actions for automatically checking your package and building/deploying a pkgdown website</li>
<li>   User interface: how to provide beautiful, informative messages with the cli package</li>
</ul>
There will be chunks of time for you to do exercises throughout the day.<br>
We will make sure there are good options that allow all participants to engage with the material.<br>
But if you have your own package(s), you are welcome to use these times to apply what we're learning, e.g., about testing or documentation, in your personal packages.
<br><br>
This will be an interactive 1-day workshop, and we will use the RStudio IDE to work through the materials.
<br><br>
This course is for you if you:
<ul>
<li>   Are very comfortable writing R scripts and functions.</li>
<li>   Have already created a basic package, e.g., you've successfully worked through <u><a href=""https://r-pkgs.org/whole-game.html""><b><u>The Whole Game chapter from R Packages</u></b></a> or have equivalent experience. You should also be able to follow the story in <u><a href=""https://r-pkgs.org/package-within.html""><b><u>The package within</u></b></a> chapter.</u></u></li>
<li>   Have concrete plans for one or more specific packages you want to create. You might have even started implementing these plans.</li>
<li>   Are interested in using devtools + Positron for package development.</li>
<li>   Are at least curious about Git/GitHub. We won't have time to teach this explicitly, but you will certainly see Git/GitHub throughout the day.</li>
</ul>
We expect most participants will have more package development experience than the minimum described above.<br>
We typically see a real mix of backgrounds in workshops such as this.<br>
Participants at either extreme (very new or very experienced) should anticipate hearing questions and discussion aimed at the other end of the experience spectrum, and that's OK.<br><br><br>

**Speaker name:** Jenny Bryan
**Job title:** Software engineer
**Company:** Posit
**Bio:**
<p>Jenny is a software engineer at Posit, usually working on the tidyverse packages or its supporting ecosystem, and is a member of the R Foundation. She recently co-authored the second edition of <a href=""https://r-pkgs.org/"" target=""_blank"">the R Packages book</a> and is the maintainer of the <a href=""https://devtools.r-lib.org/"" target=""_blank"">devtools</a> and <a href=""https://usethis.r-lib.org/"" target=""_blank"">usethis</a> packages (among others).</p>"
Workshop,Programming with LLM APIs: A Beginner’s Guide in R and Python,"## Title: Programming with LLM APIs: A Beginner’s Guide in R and Python
**Code:** WS-003
**Session type:** Workshop

**Abstract:**
Large Language Models (LLMs) open up a world of programmatic possibilities, giving developers easy access to capabilities that would have seemed like science fiction only a few years ago. But for many, the idea of integrating LLM APIs into their workflows feels daunting. This workshop is here to show you otherwise.
<br><br>
We’ll introduce you to elmer (R) and chatlas (Python), two user-friendly packages developed by Posit that make calling LLMs from code surprisingly straightforward. These tools handle the complexities of conversation history, tool calling, vision support, and more, so you can focus on experimentation and creativity. They also integrate nicely with Shiny for R and Python, where you can easily create chat interfaces or build custom web apps around LLM workflows.
<br><br>
Along the way, we’ll explore system prompt design, token management, tool calling, and structured output, all while building familiarity with the various models and vendors that are shaping the AI landscape today.
<br><br>
You’ll discover that:
<ul>
<li> Calling LLMs from code unlocks new possibilities that go far beyond what’s achievable with off-the-shelf tools like ChatGPT.</li>
<li> It’s easier than you think—no advanced AI background required.</li>
<li> It’s incredibly fun and rewarding to bring your own ideas to life.</li>
</ul>
This workshop is perfect for those curious about AI but unsure where to start, as well as for seasoned developers looking to learn about Posit’s new tools. We’ll also touch on more advanced topics like fine-tuning and Retrieval-Augmented Generation (RAG). You’ll get hands-on experience with guided projects or with the flexibility to explore using your own projects.
<br><br>
If you’ve been sitting on the fence, wondering whether LLMs are worth diving into, this workshop will give you the hands-on experience and confidence you need to get started.
<br><br>

**Speaker name:** Joe Cheng
**Job title:** CTO
**Company:** Posit
**Bio:**
Joe Cheng is the Chief Technology Officer at Posit, and the original creator of Shiny. He joined RStudio in 2009 to help create the RStudio IDE, and along the way created many web-related R packages, including htmltools, httpuv, promises, and shinymeta. He lives in the suburbs of Seattle, Washington with his wife Amy, three teenage sons, two Mazdas, and numerous bicycles.

## Title: Programming with LLM APIs: A Beginner’s Guide in R and Python
**Code:** WS-003
**Session type:** Workshop

**Abstract:**
Large Language Models (LLMs) open up a world of programmatic possibilities, giving developers easy access to capabilities that would have seemed like science fiction only a few years ago. But for many, the idea of integrating LLM APIs into their workflows feels daunting. This workshop is here to show you otherwise.
<br><br>
We’ll introduce you to elmer (R) and chatlas (Python), two user-friendly packages developed by Posit that make calling LLMs from code surprisingly straightforward. These tools handle the complexities of conversation history, tool calling, vision support, and more, so you can focus on experimentation and creativity. They also integrate nicely with Shiny for R and Python, where you can easily create chat interfaces or build custom web apps around LLM workflows.
<br><br>
Along the way, we’ll explore system prompt design, token management, tool calling, and structured output, all while building familiarity with the various models and vendors that are shaping the AI landscape today.
<br><br>
You’ll discover that:
<ul>
<li> Calling LLMs from code unlocks new possibilities that go far beyond what’s achievable with off-the-shelf tools like ChatGPT.</li>
<li> It’s easier than you think—no advanced AI background required.</li>
<li> It’s incredibly fun and rewarding to bring your own ideas to life.</li>
</ul>
This workshop is perfect for those curious about AI but unsure where to start, as well as for seasoned developers looking to learn about Posit’s new tools. We’ll also touch on more advanced topics like fine-tuning and Retrieval-Augmented Generation (RAG). You’ll get hands-on experience with guided projects or with the flexibility to explore using your own projects.
<br><br>
If you’ve been sitting on the fence, wondering whether LLMs are worth diving into, this workshop will give you the hands-on experience and confidence you need to get started.
<br><br>

**Speaker name:** Garrick Aden-Buie
**Job title:** Software Engineer, Shiny
**Company:** Posit
**Bio:**
<p>Garrick Aden-Buie is a software engineer for Shiny at Posit. He is passionate about building broadly accessible tools for data scientists in R and Python. Before joining the Shiny team, he helped build Posit Academy, an online, immersive, data science apprenticeship for professional teams. Garrick has been using and teaching Shiny since 2014, and he shares his experience and projects on his website at <a href=""https://www.garrickadenbuie.com/"" target=""_blank"">garrickadenbuie.com</a>.</p>"
Workshop,R in Production,"## Title: R in Production
**Code:** WS-001
**Session type:** Workshop

**Abstract:**
What it means to put R in production varies tremendously from organization to organization. However, I believe that there are common principles that you can learn to improve your code, regardless of the precise details of what production means for your organization.
<br><br>
This workshop is organized around three big differences between running a local script on your computer and putting your code into production:
<ul>
<li> Not just once: production code isn’t a one-off script; it runs repeatedly and needs to run reliably even as the environment around it (e.g., R package versions and input data) changes. How can you ensure that code continues to run reliably months and years after you wrote it, and when there’s a problem, it clearly reports on it?</li>
<li> Not just your computer: production code doesn’t run on your computer. It typically runs on some other server where you can’t interactively experiment. This poses particular challenges for authentication and debugging.</li>
<li> Not just you: the responsibility for production code is typically shared across a team. How can you ensure that you’re all working together as effectively as possible, sharing code and best practices, and improving at your job over time?</li>
</ul>
<br>
This course is for you if you:
<ul>
<li> Get frustrated debugging R code that’s running on another computer.</li>
<li> Struggle to keep your code running reliably as packages and data change over time.</li>
<li> Want to improve the quality of your production code generally.</li>
</ul>
<br>

**Speaker name:** Hadley Wickham
**Job title:** Chief Scientist
**Company:** Posit
**Bio:**
Hadley is Chief Scientist at Posit PBC, winner of the 2019 COPSS award, and a member of the R Foundation. He builds tools (both computational and cognitive) to make data science easier, faster, and more fun. His work includes packages for data science (like the tidyverse, which includes ggplot2, dplyr, and tidyr)and principled software development (e.g. roxygen2, testthat, and pkgdown). He is also a writer, educator, and speaker promoting the use of R for data science. Learn more on his website, .

"
Workshop,Shiny for Python,"## Title: Shiny for Python
**Code:** WS-017
**Session type:** Workshop

**Abstract:**
Shiny is a framework for building web applications and data dashboards in Python. In this one-day intermediary workshop, you will see how the basic building blocks of Shiny can be extended to create your own scalable, production-ready Python applications.
<br><br>
In particular, this workshop covers:
<ul>
<li> Overview of the basic building blocks of a Shiny for Python application </li>
<li> How to refactor applications into shiny modules </li>
<li> How to write tests for your shiny application </li>
</ul>
<br>
At the end of this workshop, you will be able to:
<ul>
<li> Build a Shiny app in Python </li>
<li> Refactor your reactive logic into Shiny Modules </li>
<li> Identify when to write Shiny modules </li>
<li> Write unit tests and end-to-end tests for your shiny application </li>
</ul>
<br>
1. What if I'm a complete beginner?
<br><br>
You should have a basic understanding of Python and be able to install packages with pip, do basic data manipulation, and draw plots.
<br><br>
2. What if I've never built a Shiny app before?
<br><br>
This workshop doesn’t require any Shiny or web application experience. We'll focus more on practical examples in the course. We do have additional resources for you to dive more into more Shiny details, but we will cover the basics needed to build larger and scalable applications.
<br><br>
3. Why should I learn Shiny if I already know Streamlit or Dash?
<br><br>
We believe that Shiny is the best framework for building data applications in Python. Its reactive execution model means that you can build performant applications without
explicitly caching data or managing the application state. See <a href=""https://posit.co/blog/why-shiny-for-python""><b><u>this blog post</u></b></a> for more on why we think that Shiny is worth learning.
<br><br>
4. I’m an expert with Shiny for R, is this workshop for me?
<br><br>
The R and Python Shiny packages are similar, so some of the content in this workshop may be familiar to you. That said, it’s a great opportunity to fill in missing pieces and ask questions about Python best practices. We will also talk about Shiny modules and testing in this workshop, which will also be a precursor for you to learn more about Python Packaging. If you are interested in learning more about Python, this workshop would be a great practical way to learn how to code in Python. Check out our <a href=""https://shiny.posit.co/py/docs/comp-r-shiny.html""><b><u>quickstart guide for R users</u></b></a> and <a href=""https://www.youtube.com/watch?v=pXidQWYY14w&ab_channel=DataUmbrella""><b><u>this tutorial</u></b></a> if you want to get up to speed with Shiny for Python quickly.

**Speaker name:** Daniel Chen
**Job title:** Data Science Educator
**Company:** Posit
**Bio:**
Daniel is a Postdoctoral Research and Teaching Fellow at the University of British Columbia and also works on the Developer Relations team as a Data Science Educator at Posit, PBC. He enjoys teaching the tooling and infrastructure around sharing and automating your data science results."
Workshop,Shiny for R,"## Title: Shiny for R
**Code:** WS-011
**Session type:** Workshop

**Abstract:**
Shiny is an R package that makes it easy to build interactive web apps straight from R. This workshop will start at the beginning: designing and implementing user interfaces, learning and understanding the reactive programming model, and deploying your Shiny apps publicly and privately. This year, we will also introduce the use of the bslib package to modernize your apps' layouts and components. The workshop will also include several intermediate-level topics like debugging and modularizing your apps and implementing dynamic user interfaces. In the end, attendees should be confident Shiny users, able to design interactive apps to achieve their purpose and produce a polished and professional implementation.
<br><br>

**Speaker name:** Colin Rundel
**Job title:** Associate Professor of the Practice
**Company:** Duke University
**Bio:**
<p><u><a href=""https://rundel.github.io/"" style=""background-color: rgb(255,255,255);font-size: 17.0px;"" target=""_blank"">Colin Rundel</a></u><span style=""color: rgb(33,37,41);background-color: rgb(255,255,255);font-size: 17.0px;""> is Associate Professor of the Practice at Duke University in the department of Statistical Science where he has been teaching since 2012. His work focuses on teaching statistical computing to both undergraduate and graduate students in both R and Python. He has been teaching and using Shiny since 2015.</span></p>"
